,Session ID,Author,Department,Abstract,Keywords
0,0,Jeroen van Baar,CLPS,"Predicting the behavior of others is an essential part of human cognition that enables strategic social behavior, such as cooperation, and is impaired in multiple clinical populations. Despite its ubiquity, social prediction poses a generalization problem that remains poorly understood: we can neither assume that others will simply repeat their past behavior in new settings, nor that their future actions are entirely unrelated to the past. Here we demonstrate that humans solve this challenge using a structure learning mechanism that uncovers other people’s latent, unobservable motives, such as greed and risk aversion. In three studies, participants were tasked with predicting the decisions of another player in multiple unique economic games. Participants achieved accurate social prediction by learning the hidden motivational structure underlying the player’s actions. This motive-based abstraction enabled participants to attend information diagnostic of the player’s next move and disregard irrelevant contextual cues. Moreover, participants who successfully learned another’s motives were more strategic in a subsequent competitive decision task with that player, reflecting the adaptive value of social prediction in everyday life. These findings demonstrate that advantageous social behavior hinges on parsimonious and generalizable mental models that leverage others’ goals and intentions.","['multiple unique economic games participants achieved accurate social prediction', 'disregard irrelevant contextual cues moreover participants', 'multiple clinical populations despite', 'ubiquity social prediction poses', 'motivebased abstraction enabled participants']"
1,0,Ifrah Idrees,Brown University - Computer Science,"The older population is set to more than double by 2050 worldwide, and conversational robots can play an essential role in improving their quality of life. In the last decade, there has been huge progress in the development of virtual conversational healthcare assistants and social robots, with emphasis on grounding natural language commands from the human to the user and having an engaging conversation with the purpose of setting medical reminders and/or to act as a companion.  We intend to build a conversational robot that can be used as a coach to help the elderly with Activities of Daily Living (ADL).  We will provide a proof of concept implementation and initial simulation results of a context-aware multi-modal dialogue manager for robots that aims to help the elderly complete the ADL safely. Our implementation interacts with the human and develops context-awareness by grounding dialogue in the sensory information received. It then fuses the current context with the user intent to learn a policy for carrying out a conversation with the elderly and guiding them in safely completing the sequential ADL task with a success rate of 73\%. We hope to work towards building a real-time multi-modal dialogue manager for robots that can generalize to all the  ADL activities. ","['setting medical reminders andor', 'realtime multimodal dialogue manager', 'contextaware multimodal dialogue manager', 'grounding natural language commands', 'virtual conversational healthcare assistants']"
2,0,Jiuyang Bai,CLPS,"For human, the ability of avoiding moving obstacle is taken for granted. However, modeling such behavior has been a long effort. Although various models have been published, few is perceptually plausible for human pedestrians. Major classes of pedestrian models rely on direct input of distance and velocity without explaining how pedestrians acquire this information. In other words, these models are based on unjustified assumptions on human perception, whereas a better model should be based on the control laws of behavior. The research I will present is about building a model of avoiding moving obstacles using visual information as the control variable. ","['avoiding moving obstacles using visual information', 'long effort although various models', 'human pedestrians major classes', 'avoiding moving obstacle', 'velocity without explaining']"
3,0,Monica Roy,Computer Science,"There are often times when we might want to be able to put robots in unknown locations and have them find specific objects in the environment for us. In some of these cases, we may know the full layout of the environment but might not want to go find the objects ourselves. For example, this could be the case if we are trying to obtain objects in a potentially hazardous environment. In such circumstances, giving the robot intermittent hints (as it is navigating the environment) about the locations of the desired objects relative to its current location should theoretically enable the robot to find the objects with greater ease and in a shorter period of time. The premise of my project is to set up a framework for a robot to take in natural language information as it navigates the unknown environment and use this to intelligently inform its search for the objects. There are two main questions that I wish to be able to answer through my project: 1. Do intermittent hints aid performance of the task? 2. How much information is necessary in order to more effectively and efficiently solve the task?","['intermittent hints aid performance', 'two main questions', 'robot intermittent hints', 'natural language information', 'desired objects relative']"
4,0,Kaiyu Zheng,Computer Science,"Humans have the ability to leverage natural language descriptions as a source of spatial information in search or navigation tasks in a new environment. Reproducing a similar ability in a robot} is of substantial benefit to untrained users who communicate via natural language, such as ``The truck is behind the building.'' However, spatial prepositions are ambiguous and subject to the speaker's personal interpretation of the scene geometry. Current approaches do not generalize to unconstrained language input or partially observable settings where the robot must act based on estimated distributions over references in the natural language. We propose a framework based on Partially Observable Markov Decision Processes (POMDPs), where information about the object location is provided in the form of spatial language observations. Additionally, we design neural network models for spatial predicates which positions and landmarks to a likelihood of the predicate holding true. For evaluation, we collect a dataset of spatial language descriptions corresponding to urban maps in 10 cities, and perform cross validation to show that our approach enables more efficient usage of the language description for object search.","['partially observable markov decision processes pomdps', 'scene geometry current approaches', 'design neural network models', 'building however spatial prepositions', 'leverage natural language descriptions']"
5,0,Gaelen Adam,"Heath Services, Policy, and Practice","Traditionally, literature identification for systematic reviews has relied on a two-step process: searching databases to identify potentially relevant citations, then manually screening those citations. We have developed a system to combine these steps, using semantic queries and human-in-the-loop semi-automation. We have developed an AI search engine that uses deep learning algorithms to find and rank relevant articles in records downloaded from MEDLINE based on a semantic query. The most relevant 100 articles are screened and tagged manually. These articles are used by the system to refine the search. This process is implemented iteratively until convergence is achieved or specified conditions are met. We will compare the sensitivity and burden of this system to the standard approach. As this project is ongoing, I will present the methods and limited empirical results from prospective application in one systematic review. A screener has annotated two sets of citations. The first 101-abstract iteration contained 41 citations that were screened as relevant, including 13 of the 79 articles in the draft report. The second included 87 new abstracts, of which 16 were screened as relevant, including an additional 6 of the 79 articles in the draft report. These preliminary results show potential for improving efficiency.","['first abstract iteration contained citations', 'uses deep learning algorithms', 'second included new abstracts', 'preliminary results show potential', 'steps using semantic queries']"
6,0,Ryan Miller,Neuroscience,"Shape recognition is a capability afforded by two principle modalities: vision and touch. Whether identifying a house key on a cluttered desk or in a pants pocket, the same basic process is being followed: collect shape information and compare it to a stored representation to determine if it is a match. Though a frequent topic of study in vision (and computer vision) research, shape recognition by touch is less well understood, as are the mechanisms supporting cross modal comparisons of shape. To explore these questions, ten participants took part in a study where they were asked to make a match/non-match determination of a large battery of serially presented novel shapes. These shapes could be presented visually or haptically and participants made comparisons both within and across modalities. We found that certain shape combinations were reliably easy or hard to compare, but that comparisons which were visually difficult weren’t necessarily the same as those that were haptically difficult. We also found that behavior on both visual-visual and haptic-haptic shape comparisons could be well predicted by shape-comparison models, but the models that work for vision are different from those that work for haptics, suggesting fundamental differences in haptic and visual shape recognition.","['questions ten participants took part', 'mechanisms supporting cross modal comparisons', 'computer vision research shape recognition', 'haptics suggesting fundamental differences', 'followed collect shape information']"
7,0,Cristina Menghini,Computer Science/Sapienza University,"The most important feature of Wikipedia is the presence of hyperlinks in pages. Link placement is the product of people's collaboration, consequently Wikipedia naturally inherits human bias. Due to the high influence that links' disposition has on users' navigation sessions, one needs to verify that, given a controversial topic, the hyperlinks' network does not expose users to only one side of the subject. A Wikipedia's topic-induced network that prevents users the discovery of different facets of an issue, suffers from structural bias. In this work, we define the static structural bias, which indicates if the strength of connections between pages of contrasting inclinations is the same, and the dynamic structural bias, which quantifies the network's level bias that users face over the course of their navigation sessions. 
Our measurements of structural bias on several controversial topics demonstrate its existence, revealing that users have low likelihood of reaching pages of opposing inclination from where they start, and that they navigate Wikipedia showing a behavior much more biased than the expected from the baselines. Our findings advance the relevance of the problem and pave the way for developing systems that automatically measure and propose hyperlink locations that minimize the presence and effects of structural bias.","['peoples collaboration consequently wikipedia naturally inherits human bias due', 'users navigation sessions one needs', 'several controversial topics demonstrate', 'navigate wikipedia showing', 'networks level bias']"
8,0,Iris Bahar,CS & Engineering,"Deep learning has gained much attention in the past few years, especially for object identification and classification problems.  Despite their strengths, neural networks have several shortcomings, such as their need for extremely large training sets, their “black box” decision making, and their inability to recover from incorrect inference.  In addition, the computational and energy resources needed to train these discriminative models can be quite immense, as they often require weeks or even months to adequately train.  Hybrid discriminative-generative algorithms offer a promising avenue for robust perception by balancing computational complexity with explainability and reasoning.  However, this approach may still not provide for real-time response to complex tasks, even after careful optimization.  Instead, we propose human-robot learning combined with complexity-aware computing to attain energy efficient real-time machine learning.  As a first goal, this research project seeks to explore how humans and intelligent computers can collaborate effectively by integrating technical functions with human cognitive processes.  A second goal is to develop complexity and energy optimized computing solutions.  The overall objective is to minimize energy consumption, improve response time, and be more likely to optimize users’ needs. ","['“ black box ” decision making', 'adequately train hybrid discriminativegenerative algorithms offer', 'minimize energy consumption improve response time', 'attain energy efficient realtime machine learning', 'propose humanrobot learning combined']"
9,1,Iris Bahar,CS & Engineering,"Deep learning algorithms based on convolutional neural networks (CNNs) have led to major improvements in accuracy for such tasks as object recognition. However, CNNs may not have sufficient robustness when presented with challenging or new scenarios (e.g, from unstructured or changing environments). Alternatively, algorithms based on Monte-Carlo
sampling have been widely adapted in robotics and other areas of engineering due to their performance robustness. However, these sampling-based approaches have high computational requirements, making them unsuitable for real-time applications with
tight energy constraints. In this talk, I will present our work on 6 degree-offreedom
(6DoF) pose estimation for robot manipulation using this method, which uses rendering combined with sequential Monte-Carlo sampling. While potentially very accurate, the significant computational complexity of the algorithm makes it less attractive for mobile robots, where runtime and energy consumption are tightly constrained. To address these challenges, we present a novel hardware implementation of Monte-Carlo sampling on an
FPGA with lower computational complexity and memory usage, while achieving high parallelism and modularization. Our results show 12X–21X improvements in energy efficiency over low-power and high-end GPU implementations, respectively. Moreover, we
achieve real time performance without compromising accuracy.","['achieve real time performance without compromising accuracy', 'results show x – x improvements', 'highend gpu implementations respectively moreover', 'changing environments alternatively algorithms based', 'object recognition however cnns may']"
10,1,Bruce Donald Campbell,Computer Science,"In this talk I would review the work we have done to look at planning methods for deploying limited physical resources (e.g. sensors) strategically to support an extended Narragansett Bay ROMS model (ocean circulation model) reasonableness check, as well as introduce a process students can use to get used to sensor techniques via virtual deployment with a web-based application. Students can then use the simulated data to pursue analysis techniques they are taught in a multiple course Proficiency of Ocean Data Science (PODS) program at the University of Rhode Island.","['extended narragansett bay roms model ocean circulation model reasonableness check', 'deploying limited physical resources eg sensors strategically', 'ocean data science pods program', 'sensor techniques via virtual deployment', 'pursue analysis techniques']"
11,1,Luke Soliman,Warren Alpert Medical School,"The Bcl-2 family of apoptotic proteins have been implicated in the progression of several human cancers, and they are thus rational targets for the treatment of these cancers. While Bcl-2 proteins play unique roles in carcinogenesis, they have also been discovered to be crucial in modifying prostate cancer growth to an androgen-independent state. Because androgen deprivation therapy constitutes the backbone of first-line treatments for metastatic prostate cancer, this phenotypic switch from an androgen-dependent to an androgen-independent growth state causes increased difficulty to deliver effective clinical treatment for these patients. In collaboration with the Lifespan Cancer Institute of Rhode Island Hospital and the Brown Center for Biomedical Informatics, this project aims to study the global mRNA expression profiles in a cohort of patients with metastatic castration-resistant prostate cancer, with a specific focus on Bcl-2. Notably, this study seeks to yield novel contributions to the field of prostate cancer research by examining the differential expression between the primary tumors and their metastatic sites, especially in regards to Bcl-2 proteins. This work leverages past advances in the molecular role of Bcl-2, and builds on them to yield clinically-relevant insights for the treatment of advanced metastatic castration-resistant prostate cancer.","['androgenindependent growth state causes increased difficulty', 'advanced metastatic castrationresistant prostate cancer', 'bcl proteins play unique roles', 'modifying prostate cancer growth', 'work leverages past advances']"
12,1,Kaiyu Zheng,Computer Science,"In search and rescue missions such as securing hostages at a bank robbery scene, an autonomous search agent must locate moving targets that could be victims or adversarial suspects. Challenges arise due to noisy, partial sensing and uncertainty over target location and behavior. Especially when faced with adversarial targets, it becomes intractable to optimally model the target’s behavior due to nested beliefs. In this work,  we formulate this domain as a multi-agent Partially Observable Markov Decision Process with factored state and observation spaces. We (hope to) investigate ways of tractably modeling the dynamic and adversarial objects from either  perspectives,  and  (hope  to)  propose  algorithms  to  efficiently  plan  under such a framework. (Hopefully), our experiment results show that our method enables efficient autonomous agents that behave competitively as their human counterparts in terms of task success rate and efficiency","['autonomous search agent must locate moving targets', 'multiagent partially observable markov decision process', 'method enables efficient autonomous agents', 'adversarial suspects challenges arise due', 'task success rate']"
13,1,Kelsey Schuch,"Molecular Biology, Cell Biology, and Biochemistry"," 	Fatigue is poorly understood, beyond muscle energetics.  For the model organism C. elegans, swimming is a more energetically costly behavior than crawling and can be classified as a form of exercise (PMID 28395669).  After prolonged swimming, C. elegans show locomotion quiescence and cycle between activity and inactivity (PMID 19011210).  The most well studied period where C. elegans show locomotion quiescence is sleep; however, we have shown that the quiescent bouts observed after prolonged swimming exercise do not fully fit the behavioral criteria required to be classified as sleep.  It is likely that this locomotion quiescence is instead indicative of a fatigue state.  Using a computer vision program and other approaches we have also tested the role of several genes previously implicated in other periods of behavioral quiescence to determine whether they also affect quiescent bouts while swimming.  We have found that while there is some overlap between genes involved in regulating behavioral quiescence during C. elegans sleep and exercise-induced quiescence, distinct pathways underlie these behaviors.  Ultimately, we hope to better understand the pathways involved in regulating quiescent bout cycling in swimming C. elegans.","['prolonged swimming c elegans show locomotion quiescence', 'poorly understood beyond muscle energetics', 'c elegans show locomotion quiescence', 'model organism c elegans swimming', 'exerciseinduced quiescence distinct pathways underlie']"
14,1,Joel K Weltman,Medicine,"The SARS-CoV-2 coronavirus is the cause of the current worldwide coronavirus epidemic. The S1 domain of SARS-CoV-2 S spike protein functions to bind the virus to the target cell surface. Binding of the virus to the cell surface is followed by penetration of the virus into the interior of the target cell. An immunological study of the SARS-CoV-2 S1 domain is presented here. This study provides computational descriptions of the S1 protein B-cell epitopes. The goal of these computations is to guide and facilitate the development of the urgently needed, clinically potent anti-SARS-CoV-2 vaccines.
    The amino acid sequence of the S1 region of the S spike protein of QHD43416 SARS-Cov-2 virus was downloaded from the NCBI website. B-cell scores were calculated for the downloaded S1 amino acid sequence with IEDB BepiPred-2.0 Sequential B-cell Epitope Predictor. Further computational processing of the immunological scores was performed with Anaconda Python 3.7.6 on a HP desktop computer running Windows 10.
 
    There are 672 amino acid positions in the coronavirus S1 domain under study. The IEDB version 2 scores computed for these S1 positions are shown in the above figure. Because of the potential medical significance of coronavirus immuno-activity, this initial study focuses on those S1 positions with the greatest predicted epitope scores. As shown as red circles in the above figure, seven peptides were observed in the S1 domain with IEDB BepiPred-2.0 scores of all component amino acids equal to or greater than 0.6 IEDB units. The positions and amino acid sequences of these seven predicted epitopic peptide components of the viral S1 protein are:
Position                                      Sequence
(10-13)                                            QLPP
(131-138)                                        YYHKNNKS
(202-206)                                        DLPQG
(238-245)                                        PGDSSSGW
(405-411)                                        IADYNYK
(449-453)                                        KPFER
(617-628)                                        TPTWRVYSTGSN

It is proposed that the methodology and results presented here can be useful for the design of a SARS-CoV-2 vaccine.

","['position sequence qlpp yyhknnks dlpqg pgdsssgw iadynyk kpfer tptwrvystgsn', 'urgently needed clinically potent antisarscov vaccines', 'iedb bepipred sequential bcell epitope predictor', 'hp desktop computer running windows', 'seven predicted epitopic peptide components']"
15,1,Hyunjoon Lee,Data Science Initiative,"Our study examined a posteriori dietary patterns across study populations in the U.S. and their association with HNC. We used individual-level pooled data on 4,539 subjects from four case-control studies (Boston, Los Angeles, New York, and North Carolina) participating in the I International Head and Neck Cancer Epidemiology (INHANCE) Consortium. We simultaneously derived shared and study-specific a posteriori patterns with a novel approach called multi-study factor analysis (MSFA) applied to 23 nutrients. We derived odds ratios (ORs) and 95% confidence intervals (CIs) for cancers of the all HNC, oral cavity and pharynx combined, and larynx, from logistic regression models. We identified four shared dietary patterns that were reproducible across studies (74% variance explained): Animal products and fats, Cereals, Antioxidant vitamins and fiber, and Dairy products. Animal products and fats was inversely associated with laryngeal cancer risk (aOR=0.62, 95% CI: 0.42–0.91, highest vs. lowest score quintile). A linearly increasing trend in HNC and laryngeal cancer risk was observed for Dairy products. We also found that a study-specific factor for North Carolina (iron, folate, and fiber) was inversely associated with HNC (aOR=0.74, 95% CI: 0.58–0.95, highest vs. lowest score tertile) and oral cavity and pharyngeal cancer risk aOR=0.71, 95% CI: 0.52–0.96).","['laryngeal cancer risk aor ci – highest vs lowest score quintile', 'hnc aor ci – highest vs lowest score tertile', 'four casecontrol studies boston los angeles new york', 'novel approach called multistudy factor analysis msfa applied', 'pharyngeal cancer risk aor ci –']"
16,1,Robin Attey,Neuroscience,"Next generation RNA sequencing (RNA-Seq) technology is a powerful tool that has led to major recent discoveries in neuroscience (‘Breakthrough of the year’, Science 2018). RNA sequencing provides information about the evolution, development, and cellular components of neural circuits. However, sequencing produces large data sets which require new and sophisticated computational tools. I have developed a new computational approach to integrate results form next generation RNA sequencing (deep-seq) and single nuclei RNA sequencing (sn-seq) of mitral and tufted cells in the mouse olfactory bulb. Analysis of single nuclei revealed distinct molecular subtypes of mitral and tufted cells. Complementary bulk deep-seq datasets were generated using retrograde viruses at different injection sites, allowing the selection of mitral and tufted cells by projection target. To integrate these datasets, I performed gene network analysis on the single nuclei, then used this gene network to simulate biologically-realistic single nuclei from each deep-seq dataset. Simulated nuclei from different retrograde injections align with different molecularly distinct subtypes of mitral cells from the sn-seq data, suggesting that molecular differences correspond to different projection targets. Simulating single nuclei from deep-seq data facilitates the integration of these two types of data, providing information that cannot be extracted from either alone.","['neural circuits however sequencing produces large data sets', 'integrate results form next generation rna sequencing deepseq', 'year ’ science rna sequencing provides information', 'next generation rna sequencing rnaseq technology', 'single nuclei revealed distinct molecular subtypes']"
17,1,Natalie Rshaidat,Computer Science and CLPS,"Facial recognition has found its way into almost every sector of society. It is something we as humans do unconsciously every day. Researching the commonalities between how our brains and how top computer facial recognition systems detect and recognize faces can aid in understanding of the brain and optimizing facial recognition systems. The goal of my project was to research if current facial recognition systems detect and recognize faces in same manner that humans do. This was done by testing if known theories of human facial recognition such as the thatcher effect, the inverse effect, and pareidolia still hold for computer facial recognition systems. Facial detection related theories were tested with multi-task cascade neural nets (MTCNN) and facial recognition related theories were tested with support vector classifiers (SVC).  This research discusses computational facial recognition models in comparison to known theories on the human brain's mechanisms of facial recognition.","['computer facial recognition systems facial detection related theories', 'top computer facial recognition systems detect', 'research discusses computational facial recognition models', 'current facial recognition systems detect', 'multitask cascade neural nets mtcnn']"
18,2,Daniel,Li,"Machine learning has grown in use within the particle physics community to perform various tasks such as classifying signal versus background events and applying regression analysis to detector response corrections.  More recently, neural networks have been used to identify physically relevant characteristics of such events in a framework known as Variable Importance. In Variable Importance, a variable’s importance is quantified using the differential between the classification discriminator, the area under a receiver operating characteristic (ROC) curve,  from two trained networks.  One network has n inputs (seed) while another has n-1 inputs (subseed) where the excluded variable is being evaluated.  Variable Importance is discussed in context of the search for four top quark productions from proton-proton collisions at a center-of-mass energy of 13 TeV at the Large Hadron Collider (LHC) detected using the Compact Muon Solenoid (CMS) detector.  Data samples are generated using Monte Carlo, simulating both particle production and detector interactions.  Importance ranking results from a preliminary survey of multivariate variables is presented.","['compact muon solenoid cms detector data samples', 'large hadron collider lhc detected using', 'receiver operating characteristic roc curve', 'generated using monte carlo simulating', 'two trained networks one network']"
19,2,Shahrzad Haddadan,Computer Science,"Given a knowledge network like Wikipedia or a recommender system like Youtube or Amazon, users explore it by sequentially clicking links. A web surfer keen to learn about a topic explores a part of the network, and she is exposed to different, often opposing views. We say a surf is biased if all of the visited pages express the same view. If the topology of the links directs most of the users to biased surfs we say the network is ``structurally biased''

This work aims to define and measure structural bias in a network, and to suggest algorithms to decrease it. Assuming that pages in the network are labeled blue or red, we provide the following contributions:  
Firstly, for any page in the network, we define its ``bubble diameter'' to be the expected number of steps a surfer needs to take to visit a page of the opposite color. Secondly, to measure the structural bias of the network, we suggest efficient algorithms to find ``bad'' pages in the network: those pages whose bubble diameter is high. Thirdly, we devise efficient algorithms to modify the network and decrease the structural bias with little modification. Eventually, we apply our methods on real networks, i.e. Wikipedia and Amazon, and compare our results to other approaches.","['recommender system like youtube', 'real networks ie wikipedia', 'different often opposing views', 'knowledge network like wikipedia', 'pages whose bubble diameter']"
20,2,Seiji Shaw,Computer Science,"When humans plan to execute a new manipulation task, we do so by reasoning about the sequence of sub-tasks for successful execution. When repeating the task in novel environments resequencing of the tasks may be required, or additional subtasks may need to be introduced. Composing behavior from modular and composable units simplifies each learning task and vastly broadens the capabilities of the agent.

We formulate a novel representation of these subtasks, called a composable interaction primitive (CIP). Each CIP defines an initiation component that encapsulates the robot’s movement to a starting configuration for the execution of the subtask. While the desired motion trajectory of an initiation component can be solved using existing planning algorithms, they are prohibitively slow to recompute trajectories when tasks are resequenced in real-time.

We are considering locally-reactive motion-policies, which gives easier-to-compute robot accelerations based on proximity to local obstacles in the environment and goal configuration. Designing a single motion-policy to handle all obstacle avoidance and goal-reaching behavior is difficult. A promising computational framework, RMPFlow, allows us to define many motion policies that handle each objective separately (obstacle avoidance, goal-reaching, etc) and then synthesize them to compute a single policy to guide motion for the CIP initiation component.","['promising computational framework rmpflow allows us', 'objective separately obstacle avoidance goalreaching etc', 'solved using existing planning algorithms', 'gives easiertocompute robot accelerations based', 'define many motion policies']"
21,2,Caleb Trotz,Computer Science,"	Authoring 3D shapes by hand is time-consuming and inefficient for non-experts. Generative models provide compelling alternatives that capture a wide range of modes of variability in a given object class. For shapes with underlying hierarchical structure, such as part-based shapes, works in press introduce a generative model that captures purely structural variability, enabling coarse representation of each member of an object class. This generative model, a hierarchical Variational Auto-Encoder (VAE), encodes and reconstructs programs in a domain-specific language called ShapeAssembly. ShapeAssembly programs describe how to construct a series of bounding cuboids that represent the part hierarchy of the original shape. One fundamental problem remains: generating fine-grained geometry from this structural prior. 
We propose a generative model conditioned on the latent encodings from ShapeAssembly that learns the style of the shape. This generative model regresses a Signed Distance Function (SDF), which produces the signed distance from a point in ℝ3 to the surface of the shape, indicating whether a point is inside or outside the surface. Various neural network architectures are proposed to regress the SDF, including a Conditional Auto-Decoder and a Conditional VAE. We hypothesize that generating geometry conditioned on the entire shape’s structure will outperform part-level geometry generation.","['original shape one fundamental problem remains generating finegrained geometry', 'captures purely structural variability enabling coarse representation', 'domainspecific language called shapeassembly shapeassembly programs describe', 'nonexperts generative models provide compelling alternatives', 'surface various neural network architectures']"
22,2,Aarit Ahuja,Neuroscience,"The ability to predict future occurrences is a fundamental aspect of daily life. One way to engage in prediction can be through mental simulation. Simulation entails experiencing hypothetical versions of external events in the absence of sensory input. The result of a simulated experience may be used to guide a prediction of the future. It is possible to test the simulation hypothesis through our interactions with moving objects. As movement is inherently extended in time, one might rely on simulation to prospect on an object’s motion trajectory. Despite the intuitive appeal of simulation for prediction, empirical evidence for internal simulation of motion in humans has not been clear. Further, it is not known whether nonhuman primates (NHPs) possess this mental faculty. We have conducted a series of human and primate behavioural experiments showing that members of both species are able to employ simulation to solve complex problems of motion prediction. Preliminary human fMRI data further support the simulation hypothesis and show that motion-responsive regions of the brain are activated as subjects attempt to predict an object’s future path. We are currently collecting primate fMRI data as well, and will thus elucidate the neural mechanisms of simulation across species.","['mental simulation simulation entails experiencing hypothetical versions', 'known whether nonhuman primates nhps possess', 'motion prediction preliminary human fmri data', 'currently collecting primate fmri data', 'primate behavioural experiments showing']"
23,2,Linda Yu,Neuroscience,"Flexible, adaptive behavior requires learning structure from previous experiences that can generalize to completely novel situations. Although structure learning is critical to our ability to navigate the world and quickly adapt to new situations, it is not well understood how our brains instantiate this type of learning. Recently, an exciting new area of research proposes that a neural system previously known to underlie spatial navigation – the entorhinal grid cell system – may actually serve as a general mechanism for navigating not just physical spaces, but cognitive ones as well. We investigate whether such abstract grid representations might facilitate the transfer of information from one environment to another. We developed a task in which abstract grid representations can be dissociated through neuroimaging from more standard spatial grid representations, and test which of these patterns is observed in the concurrent with task performance, and the degree to which such patterns relate to behavioral measures of transfer learning. Our preliminary data show that participants are able to learn the abstract task structure and transfer it to novel stimuli and environments consistent with zero-shot learning, and that brain regions of interest encode abstract grid representations of the form that could facilitate such transfer.","['entorhinal grid cell system – may actually serve', 'flexible adaptive behavior requires learning structure', 'completely novel situations although structure learning', 'interest encode abstract grid representations', 'abstract grid representations might facilitate']"
24,2,Rex Liu,CLPS,"In spite of their great success at attaining superhuman performance in a wide range of tasks, artificial agents have shown extremely limited ability to generalise beyond the narrow settings in which they were trained. In contrast, one of the hallmarks of human intelligence is our ability to take knowledge acquired in familiar settings and transfer it to novel ones that share some underlying similarity. One key difference is that most tasks are highly structured and humans readily exploit this structure to help transfer knowledge; artificial agents, on the other hand, treat tasks as monolithic entities. In this work, we train agents to navigate a series of rooms using a hierarchical Dirichlet process model of the task structure. The model can be regarded as a generative model of the task structure. As the agent interacts with the environment, it learns both the elements of the hierarchy — in this case the reward and mapping functions — as well as the statistical correlations between them. When interacting with a novel room context, the agent can choose whether to transfer pre-existing knowledge about these elements and their correlations or whether to learn any of these de novo. Our agent is therefore able to transfer knowledge in a more compositional manner, thus allowing for faster adaptation to novel settings.","['underlying similarity one key difference', 'help transfer knowledge artificial agents', 'compositional manner thus allowing', 'shown extremely limited ability', 'hierarchical dirichlet process model']"
25,2,Olga Lositsky,CLPS,"How do we learn task representations that are general enough to span multiple contexts yet specific enough to maximize reward for a given context? In a series of experiments, Gershman et al. (2013, 2014) provided evidence that humans use Occam’s razor when grouping perceptual representations by context: observations are grouped together so long as they are similar enough, and only separated by context when the contexts make sufficiently different predictions. In situations when the world is constantly changing, their theory predicts that people will incorporate new information into their existing representation so long as it is not too surprising. However, large prediction errors should serve as a signal that the situation has changed and a new representation should be created. In this experiment, we tested whether the above theory predicts how task representations are learned in a changing environment. Our results suggest that when feedback changed gradually over time, participants grouped incoming observations with their existing task representation, which caused modification of the task set memory. In contrast, changing the feedback abruptly caused the creation of a new task set and prevented the initial memory from interference.","['experiments gershman et al provided evidence', 'span multiple contexts yet specific enough', 'contexts make sufficiently different predictions', 'surprising however large prediction errors', 'time participants grouped incoming observations']"
26,2,Emily Chicklis,CLPS,"Neural representations have the geometric property of dimensionality, which reflects both how neurons encode information as well as the accessibility of that information. High-dimensional representations are characteristic of the prefrontal cortex (pFC), but such representations can be difficult to decode with typical pattern analysis methods.

In 2016, Rigotti and Fusi’s paper “Estimating the dimensionality of neural responses with fMRI Repetition Suppression” introduced a novel, adaptation-based simulation for estimating the dimensionality of neural responses. However, the simulation models the blood-oxygen-level-dependent (BOLD) response as a linear sum of spiking activity. This methods project attempts to replicate a key finding from that paper after incorporating the canonical BOLD time course: namely, that the simulation method produces dimensionality
estimates that are highly correlated with the true dimensionalities. This correlation is in fact replicated, though differences from the 2016 paper do emerge. Overall, this simulation remains a promising method for realistically estimating dimensionality in areas like the pFC.","['fmri repetition suppression ” introduced', 'canonical bold time course namely', 'simulation method produces dimensionality estimates', 'fact replicated though differences', 'typical pattern analysis methods']"
27,3,Xavier Coubez,Department of Physics,"Jet classification and application to Higgs physics in the CMS Collaboration at the LHC

In particle physics at hadron colliders such as the LHC, jet classification is the task of separating sprays of particles emerging from the decay of different elementary particles called quarks using their properties. In the last few years, such algorithms have benefited from the use of increasingly complex deep neural network architectures. This challenging classification task has been a key element of analyses studying the coupling of the Higgs boson to quarks. Improved performance are now allowing to probe physics processes thought to be unreachable. Brown CMS group has been historically involved in developing algorithms to classify jets, study the agreement between simulation and the data taken with the CMS detector, and deriving corrections to the simulation to match the data.

The talk will cover the strategy followed during the last years to improve performance of algorithms, as well as two analyses who benefited from such developments and allowed to probe with unprecedented precision the coupling of the Higgs boson to quarks. It will open on some new challenges particle physics is facing, related to the use of more and more advanced machine learning techniques.
","['increasingly complex deep neural network architectures', 'different elementary particles called quarks using', 'advanced machine learning techniques', 'unreachable brown cms group', 'new challenges particle physics']"
28,3,Ivan Felipe Rodriguez,CLPS/Carney Institute,"Taxonomy in living plants is highly dependent on visual features that can be observed at naked eye. However when more details and complex structures are needed in order to further comprehend the division among families, species, etc. ML methods can be of benefit as they dinamically are able to learn an embedded representation of  these features and possibly even a non-trivial combination of them, generating a reliable distinction. In this work, we want to extend this idea into an even harder problem. We would use photos of extinct fossil leafs to perform a matching to living leafs, in effect finding the closest living parent of a  dead leaf. Given the scarcity of the samples available for fossils, we propose a style transfer approach that let us leverage the  availability of cleared leafs. And in order to maintain the structure of the representation, we use a triplet loss that combines in-style and transfer style sampling to achieve cross domain representation.  ","['division among families species etc ml methods', 'achieve cross domain representation', 'transfer style sampling', 'style transfer approach', 'naked eye however']"
29,3,Diana Burk,Neuroscience,"As we move throughout the world, our brains continuously acquire sensory information and make predictions when visual information is limited. For example, an animal hopping in a foggy park could be perceived as a rabbit or a frog, even when the animal’s shape is obscured. How does the hopping movement lead to potential animal identity? More generally, objects often have stereotypical movements, but it remains unknown how movement is used in object recognition. Previous research has shown that the brain associates features (e.g. color, shape, size) to create a unified percept of an object. Here we ask how motion might affect shape-sensitive responses in inferior temporal cortex during a task that requires selection of shapes based on motion information. Monkeys were trained to match moving shapes with variable perceptual noise.  A pattern classifier was used to decode motion pattern identity from a population of IT neurons recorded while monkeys did the task.  Preliminary data suggests that some neurons in inferior temporal cortex indeed have access to motion information that could support moving object recognition.","['brain associates features eg color shape size', 'motion might affect shapesensitive responses', 'brains continuously acquire sensory information', 'could support moving object recognition', 'object recognition previous research']"
30,3,Minju Jung,CLPS,"Abstract reasoning is one of the measures of intelligence for humans as well as for machines. Raven’s Matrices is one such task humans have used to estimate their visual reasoning. Recently, there are studies to bring the power of deep learning into Raven’s Matrices and achieve near-human-level performance on the trained rules. However, when these models are exposed to similar test rules, their performance is far from that of humans; the reason being their inability in finding relational structure. We would like to propose a model which can generalize to unknown rules in order to be truly machine-intelligent. For this we choose a meta-learning framework which will enable it to infer new tasks(rules). To accomplish this, we convert the progressive matrices into a meta-learning framework. In this, the inner loop optimizes the process of inferring the correct rules for the matrix, and an outer loop which optimizes the inference procedure of the inner loop. This enables the inference procedure to get better over time, thereby enabling it to learn new rules.","['time thereby enabling', 'infer new tasksrules', 'finding relational structure', 'trained rules however', 'similar test rules']"
31,3,Laura Mercurio,Pediatric Emergency Medicine & Brown Center for Biomedical Informatics/Brown University ,"Sepsis is a leading cause of serious illness and death among U.S. children. It is the leading cause of inpatient pediatric mortality, representing 7-9% of all pediatric deaths. Pediatric sepsis presents on a spectrum, and overlaps routine illness; there is limited knowledge regarding risk factors for otherwise healthy children developing this condition. Our aim was to examine “patient state” characteristics – those features that do not vary based on healthcare team – and their association with sepsis among children 0-18 years of age presenting to a children’s hospital emergency department with fever or infectious complaint. We hypothesized that broad consideration of structured data elements would yield novel risk factors for pediatric sepsis. We incorporated structured data elements from the electronic health record (EHR) into several candidate models, identified the most sensitive model, and examined those features enabling the model to successfully identify septic patients. Our top-performing model was a random forest classifier; its top features reinforced the well-established clinical association between tachycardia, hypotension, and sepsis. Up-to-date immunization status also appeared among the top ten contributing features, reaffirming the importance of childhood vaccination in preventing sepsis. Our study highlights the importance of recognizing tachycardia, hypotension, and incomplete immunization status when assessing risk for pediatric sepsis. ","['structured data elements would yield novel risk factors', 'examine “ patient state ” characteristics –', 'sepsis uptodate immunization status also appeared among', 'limited knowledge regarding risk factors', 'incorporated structured data elements']"
32,3,Remi Cadene,Brown,"Machine learning models tend to over-rely on statistical shortcuts. These spurious correlations between parts of the input and the output labels do not hold in real-world settings. We target this issue on the recent open-ended visual counting task which is well suited to study statistical shortcuts. We aim to develop models that learn a proper mechanism of counting regardless of the output label. First, we propose the Modifying Count Distribution (MCD) protocol, which penalizes models that over-rely on statistical shortcuts. It is based on pairs of training and testing sets that do not follow the same count label distribution such as the odd-even sets. Intuitively, models that have learned a proper mechanism of counting on odd numbers should perform well on even numbers. Secondly, we introduce the Spatial Counting Network (SCN), which is dedicated to visual analysis and counting based on natural language questions. Our model selects relevant image regions, scores them with fusion and self-attention mechanisms, and provides a final counting score. We apply our protocol on the recent dataset, TallyQA, and show superior performances compared to state-of-the-art models. We also demonstrate the ability of our model to select the correct instances to count in the image. Code and datasets are available: https://github.com/cdancette/spatial-counting-network","['model selects relevant image regions scores', 'recent openended visual counting task', 'modifying count distribution mcd protocol', 'show superior performances compared', 'spatial counting network scn']"
33,3,William Zhang,Applied Math,"Title: Investigating collective behavior in active matter using topological data analysis
In this talk I will introduce topological data analysis (TDA), a powerful tool for characterizing the ‘shape’ of data. I will demonstrate how TDA is used to extract a topological barcode which corresponds to the presence of connected components, loops, voids and high dimensional ‘holes’ in point cloud data. The barcode provides a unique insight into the spatial organization of data, which is often missing from typical analyses based on machine learning and statistics. Consequently, TDA has found many applications in engineering and science ranging from genetics to astronomy. My lab is interested in developing novel applications of TDA to investigate active matter, such as collective behavior observed during cell sorting, tumorigenesis and cancer metastasis. I will outline a methodology based on TDA that can be used to identify phase transitions and distinct patterns of collective behavior in simulations of self-propelled interacting particles, inspired from experimental observations in developmental and cancer biology.
","['active matter using topological data analysis', 'high dimensional ‘ holes ’', 'introduce topological data analysis tda', 'selfpropelled interacting particles inspired', 'connected components loops voids']"
34,3,Gabriel Monteiro da Silva,MCB,"Despite our best efforts, traditional drug design and screening methods have historically trailed the accelerated mutation rates of pathogens, highlighting the dire need for accurate and fast predictive simulations of molecular evolution. In this study, we combine homology modeling and molecular docking as predictive tools supported by experimental data to systematically probe the effects of dozens of point mutations in the antibiotic hydrolyzing enzyme TEM beta-lactamase. We propose a mechanism for a previously-unreported resistance-conferring mutation. Our results could prove useful for guiding the rational design of next generation beta-lactamic antibiotics, and hopefully bring us closer to finally taking the lead against the looming threat of multi-resistant bacteria.","['antibiotic hydrolyzing enzyme tem betalactamase', 'best efforts traditional drug design', 'results could prove useful', 'next generation betalactamic antibiotics', 'hopefully bring us closer']"
35,4,Xiamin Leng,"Cognitive, Linguistic and Psychological Sciences, Carney Institute for Brain Science","When deciding how to allocate cognitive control to a given task, people must consider both positive outcomes (e.g., praise) and negative outcomes (e.g., admonishment). However, it is unclear how these two forms of incentives differentially influence the amount and type of cognitive control a person chooses to allocate. To address this question, we had participants perform a self-paced incentivized cognitive control task, varying the magnitude of reward for a correct response and punishment for an incorrect response. Formalizing control allocation as a process of adjusting parameters of a drift diffusion model (DDM), we show that participants engaged in different strategies in response to variability in reward (adjusting drift rate) versus punishment (adjusting response threshold). We demonstrate that this divergent set of strategies is optimal for maximizing reward rate while minimizing effort costs. Finally, we show that these dissociable patterns of behavior enable us to estimate the motivational salience of positive versus negative incentives for a given individual.","['reward adjusting drift rate versus punishment adjusting response threshold', 'selfpaced incentivized cognitive control task varying', 'given task people must consider', 'negative outcomes eg admonishment however', 'incorrect response formalizing control allocation']"
36,4,Tiantian Li,Neuroscience,Two competing theories have been proposed in literature about the exact functions of fluctuations in arousal and their relationship with changes in the brain’s information processing state. One theory suggests that the arousal system has a normative relationship with learning and the adjustment of learning rate. An alternative theory suggests that the arousal system has an important role in down-regulation of biases that influence perception and decision making. Here we develop a paradigm that can distinguish between these alternate theories by measuring pupil diameter and EEG markers of arousal during in a novel learning and perception task. We will discuss the experimental setup and present some preliminary results from computational modeling and EEG and eye-tracking data collection.,"['information processing state one theory suggests', 'alternative theory suggests', 'measuring pupil diameter', 'eyetracking data collection', 'two competing theories']"
37,4,Nihal Nayak,Department of Computer Science/Brown University,"Zero-shot learning relies on semantic class representations such as attributes or pretrained embeddings to predict classes without any labeled examples. We propose to learn class representations from common sense knowledge graphs. Common sense knowledge graphs are an untapped source of explicit high-level knowledge that requires little human effort to apply to a range of tasks. To capture the knowledge in the graph, we introduce ZSL-KG, a framework based on graph neural networks with non-linear aggregators to generate class representations. Whereas most prior work on graph neural networks uses linear functions to aggregate information from neighboring nodes, we find that non-linear aggregators such as LSTMs or transformers lead to significant improvements on zero-shot tasks. On two natural language tasks across three datasets, ZSL-KG shows an average improvement of 9.2 points of accuracy versus state-of-the-art methods. In addition, on an object classification task, ZSL-KG shows a 2.2 accuracy point improvement versus the best methods that do not require hand-engineered class representations. Finally, we find that ZSL-KG outperforms the best performing graph neural networks with linear aggregators by an average of 3.8 points of accuracy across these four datasets.","['two natural language tasks across three datasets zslkg shows', 'common sense knowledge graphs common sense knowledge graphs', 'graph neural networks uses linear functions', 'object classification task zslkg shows', 'require handengineered class representations finally']"
38,4,Michelle Akerman,School of Engineering,"Clinical trials of Deep Brain Stimulation (DBS) for depression have shown promise. DBS consists of the surgical placement of electrodes to electrically stimulate deep areas in the brain like the ventral capsule/ventral striatum (VC/VS) at high frequencies in order to alleviate symptoms. However, there exists a lack of understanding in brain circuits involved in depression, and how DBS affects these circuits.

The objective of this project is to characterize neural activity during varying stimulation parameters for DBS, specifically in brain regions involved in reward processing in depression. In a patient with Treatment-Resistant Depression (N=1), resting state intracranial recordings were conducted in the orbitofrontal cortex while performing high frequency (130 Hz) and low frequency (50 Hz) stimulation in the VC/VS. Here, we report the differences in spectral power, specifically theta (4-7 Hz), beta (13-30 Hz) and gamma (30-140) frequency bands in the orbitofrontal cortex, between high frequency and low frequency stimulation conditions. We hope that over the course of the investigation, the results of this analysis will help better understand reward circuitry in the brain of individuals with Treatment-Resistant Depression (TRD). ","['treatmentresistant depression n resting state intracranial recordings', 'spectral power specifically theta hz beta hz', 'help better understand reward circuitry', 'low frequency hz stimulation', 'electrically stimulate deep areas']"
39,4,Chen Ming,Neuroscience,"Big brown bats transmit wideband FM biosonar sounds that sweep from 55 to 25 kHz (1st harmonic, FM1) and from 110 to 50 kHz (2nd harmonic, FM2). In dense, extended biosonar scenes, bats have to emit sounds rapidly to avoid collisions with near objects. But, if a new broadcast is emitted when echoes of the previous broadcast still are arriving, echoes from both broadcasts intermingle, creating ambiguity about which echo corresponds to which broadcast. One known solution is bats create consecutive echolocating calls with small frequency shifts (around 5 kHz) in the tail-end of FM1, so echoes from different broadcasts are grouped by carrying the same tail-end frequency as their corresponding pulses. But, computationally, how are echoes with a higher tail-end frequency as previous calls rejected in the auditory system while bats are analyzing echoes from the current call? We show that echoes need only the lowest FM1 broadcast frequencies of 25-30 kHz for delay perception. If these frequencies are removed, no delay is perceived. The bat-inspired Spectrogram Correlation and Transformation (SCAT) model also begins at the lowest frequencies; echoes that lack them are eliminated from processing of delay and no longer cause ambiguity.","['big brown bats transmit wideband fm biosonar sounds', 'dense extended biosonar scenes bats', 'transformation scat model also begins', 'bats create consecutive echolocating calls', 'small frequency shifts around khz']"
40,4,Avinash Vaidya,"Cognitive, Linguistic and Psychological Sciences","Many complex tasks we perform, though different in their details, share a common abstract structure. Learning this structure is thought to underlie our ability to rapidly generalize our knowledge to unique problems we have never encountered before. However, evidence of such abstract task representations in the brain during generalization is limited. In a functional magnetic resonance imaging (fMRI) experiment, we tested for pattern activity in the human brain consistent with an abstract task representation needed for generalization. Human participants learnt the value of three different image categories in nine different observable contexts. Critically, these contexts could be clustered around three ‘latent states’ based on the similarity of their category-value associations. Participants were then trained on the value of three new image categories in one context from each latent state. Finally, in the scanner, participants had to transfer information about the value of these new categories to the two held-out contexts based on their shared latent states without any new feedback. We found that pattern activity within the rostrolateral prefrontal cortex, inferior parietal lobule and precuneus was consistent with the representation of latent states bridging contexts during this generalization phase. These results provide a new understanding of the neural systems supporting the execution of complex tasks with limited training.","['clustered around three ‘ latent states ’ based', 'rostrolateral prefrontal cortex inferior parietal lobule', 'functional magnetic resonance imaging fmri experiment', 'nine different observable contexts critically', 'shared latent states without']"
41,4,Sahar Shahamatdar,Center for Computational Molecular Biology,"Lung cancer is the primary cause of cancer death in the US, accounting for 22.4% of deaths, with adenocarcinoma as the most common subtype. Treatment for patients with lung adenocarcinoma is informed by histopathological analysis and molecular testing. Rich phenotypic information is embedded in histology, including the effect of genomic alterations on morphology. Here, we developed an attention-based deep learning model to infer the presence of KRAS mutations from histopathology slides. We trained and tested our model on 155 slides from patients with lung adenocarcinoma. Thirty one of these slides were further processed using laser capture microdissection (LCM). We first developed an encoder model to transform each slide into a lower dimensional feature space as whole slide images are too large to be directly inputted into neural networks. Using the transformed slides, we trained a convolutional neural network with the inclusion of the global-and-local attention (GALA) module. We trained the model with an additional loss that evaluates the difference between attention maps derived by GALA and our LCM dataset. The test accuracy was 80%. Broadly, these results allow for rapid characterization of KRAS mutations in lung adenocarcinoma and identification of morphological features that can aid physicians with therapeutic decisions.","['processed using laser capture microdissection lcm', 'molecular testing rich phenotypic information', 'lower dimensional feature space', 'attentionbased deep learning model', 'globalandlocal attention gala module']"
42,4,Isa Milefchik,Brown Computer Science,"I am working towards an improved algorithm to generate realistic foreground objects within existing background images using a generative adversarial network (GAN). Previous work on this task has been accomplished in Professor James Tompkin's lab, and I seek to improve upon this work by enabling better control by the user over the generated foreground object's appearance.

The generation of foreground objects is divided into two separate steps: mask and texture generation. The goal of mask generation is to produce a realistic shape or silhouette of a given object class (e.g., giraffe, zebra, car, etc.). Texture generation is then conditioned on the object shape and aims to produce a realistic texture of the object class within it.

A current avenue of investigation in my research is the conditioning of mask generation on user-defined object landmarks in three-dimensional space. These landmarks can then be projected down onto the image plane and factored into mask generation. This would give the user direct control over the shape and pose of the generated foreground object.","['given object class eg giraffe zebra car etc texture generation', 'generate realistic foreground objects within existing background images using', 'generative adversarial network gan previous work', 'generated foreground objects appearance', 'object class within']"
43,5,Stephanie Vartany,Brown Neuromotion Lab,"Major Depressive Disorder is a highly prevalent psychiatric illness, affecting more than 3 million patients per year in the United States. Up to one third of these cases do not respond to standard psychotherapeutic or pharmacological treatments and are classified as Treatment Resistant Depression (TRD). In addition to mood state impairment, deficits in cognitive control have been observed in TRD. Deep Brain Stimulation (DBS) has shown promise for treatment of TRD and improvement of cognitive deficits. However, the underlying neural mechanisms are unknown both for observed cognitive impairment in TRD and symptom improvement caused by DBS. This study focuses on characterizing neural activity in the theta band (4-7 Hz), which is hypothesized to be involved in cognitive control, and understanding how this activity is affected by DBS in TRD. Intracranial recordings were performed in a patient with TRD (n = 1) during a parametric cognitive control task before and after DBS. In the task, the patient was presented with a field of randomly moving colored dots and was instructed to ignore distractors to report the most prevalent color. Here, we present preliminary results showing differences in various methods of wavelet decomposition and modulation of theta power in pre- and post-stimulation conditions.","['present preliminary results showing differences', 'highly prevalent psychiatric illness affecting', 'trd deep brain stimulation dbs', 'randomly moving colored dots', 'million patients per year']"
44,5,Josh Roy,Computer Science,"We introduce Wasserstein Adversarial Proximal Policy Optimization (WAPPO), a novel algorithm for visual transfer in Reinforcement Learning that explicitly learns to align the distributions of extracted features between a source and target task. WAPPO approximates and minimizes the Wasserstein-1 distance between the distributions of features from source and target domains via a novel Wasserstein Confusion objective. WAPPO outperforms the prior state-of-the-art in visual transfer and successfully transfers policies across Visual Cartpole and two instantiations of 16 OpenAI Procgen environments.","['introduce wasserstein adversarial proximal policy optimization wappo', 'successfully transfers policies across visual cartpole', 'novel wasserstein confusion objective wappo outperforms', 'target task wappo approximates', 'target domains via']"
45,5,Rebecca Burwell,CLPS,"The Role of the Pulvinar in Higher Cognitive Functions  The pulvinar, called the lateral posterior nucleus of the thalamus in rodents, is one of the higher-order thalamic relays and the main visual extrageniculate thalamic nucleus in primates and rodents. The pulvinar provides the primary thalamic input to the posterior parietal cortex (PPC). Both the pulvinar and the PPC are known to be important for visuospatial attention (VSA). Previously, we showed that neuronal activity in the PPC correlates with onset of the visual stimuli, decision-making, task-relevant locations, and behavioral outcomes. We hypothesized that the pulvinar supports these functions. Accordingly, we recorded neuronal activity in the pulvinar in rats during performance on a VSA task designed to engage goal-directed, top-down attention and stimulus-driven, bottom-up attention. Rats monitored three locations for the brief appearance of a target stimulus and approached the correct target location for a liquid reward. We analyzed behavioral epochs demarcated by stimulus onset, selection behavior, and reward approach. Neurons in the pulvinar signaled stimulus onset and selection behavior consistent with the interpretation that the pulvinar is engaged in both bottom-up and top-down visuospatial attention. Our results also showed that pulvinar cells responded to allocentric and egocentric task-relevant locations.","['stimulusdriven bottomup attention rats monitored three locations', 'visual stimuli decisionmaking taskrelevant locations', 'main visual extrageniculate thalamic nucleus', 'engage goaldirected topdown attention', 'visuospatial attention vsa previously']"
46,5,Matt Ricci,DSI,"Synchronization in complex, nonlinear systems is mysterious and beautiful. To aid in the exploration of this phenomenon, we introduce ""Kura-Net"", a machine learning system for optimizing graph structures conducive to global synchrony in a network of Kuramoto oscillators. The system uses a parametrized function to model a distribution on connectivity matrices conditioned on a pattern of intrinsic oscillator frequencies. The parameters of this function are adjusted by gradient descent so that the distribution is gradually shaped to encourage emergent synchrony. We demonstrate how Kura-Net learns connectivity structures different than those previously implicated in the literature and analyze these structures by various graph theoretic means. We briefly note some applications, notably to systems and computational neuroscience, where we draw an analogy between the patterns of connectivity learned by our system and those found in cortical networks.","['kuranet learns connectivity structures different', 'various graph theoretic means', 'optimizing graph structures conducive', 'connectivity matrices conditioned', 'intrinsic oscillator frequencies']"
47,5,Elaheh Raisi,Computer Science,"In this research, we propose a learning algorithm for training deep neural networks when there is not sufficient labeled data. To improve the generalization capabilities of the deep model, we adopt a learning scheme to train two related tasks simultaneously. One is the original task (target), and the other is an auxiliary task (source). In order to create a related auxiliary task, we leverage an available knowledge graph to query for semantically related concepts that are grounded in labeled images; hence we call our method KGAuxLearn. We jointly train the target and source tasks in a multi-task architecture. We evaluate our method on two fine-grained visual categorization benchmarks: Oxford Flowers 102 and CUB-200-2011. Our experiments demonstrate that the error rate reduced by at least 2.1% over fine- tuning for both datasets. We also improve the error rate by 1.36% and 2.93% over using randomly selected concepts as an auxiliary task for Oxford Flowers 102 and CUB-200- 2011, respectively.","['two finegrained visual categorization benchmarks oxford flowers', 'train two related tasks simultaneously one', 'using randomly selected concepts', 'training deep neural networks', 'semantically related concepts']"
48,5,Mohit Vaishnav,CLPS,"Feedforward neural networks are now achieving superhuman accuracy in various image categorization tasks including face recognition, object recognition, and scene parsing. However, these same architectures struggle to learn basic visual relations such as judging whether two or more items in a visual scene are the same or different. Here,  we use the “Synthetic Visual Reasoning Test”  (SVRT) challenge to identify the minimal set of neural computations necessary to solve all 23 visual reasoning problems. Our results lead to a refinement of the visual reasoning taxonomy found by (Kim*, Ricci* & Serre, 2018). In particular, we identify clusters of tasks that require spatial attention, some that require feature-based attention, and some that require both.","['various image categorization tasks including face recognition object recognition', '“ synthetic visual reasoning test ” svrt challenge', 'visual reasoning taxonomy found', 'learn basic visual relations', 'visual reasoning problems']"
49,5,Rachel Rac-Lubashevsky,CLPS,"Computational models of fronto-striatal circuitry propose that working memory (WM) is controlled through a selective gating mechanism which is modifiable by reinforcement learning. This gating mechanism is hypothesized to operate at multiple levels. The input gating mechanism controls whether and how new information is updated in WM. The output gating mechanism controls which information within WM is selected to guide behavior. Finally, the motor gating controls the selection of actions. In the present study, the reference–back task was adapted to learn about the mechanisms that underlie selective input and output gating in humans. EEG recordings were used to examine how the control functions involved in gating are mapped to different neural signatures. Behavior and EEG results suggest that input, output, and response gating mostly operate in parallel. Using a univariate decoding analysis of the EEG data with the hierarchical drift-diffusion model (HDDM) of decision making, we showed that trial by trial increase in neural activity related to response gate switching predicted increase in the decision threshold (the threshold for evidence accumulation) of response selection only when no cognitive conflict was present. These findings demonstrate that information selection in WM can override the effect of motor gating.","['response gate switching predicted increase', 'input gating mechanism controls whether', 'reference – back task', 'hierarchical driftdiffusion model hddm', 'different neural signatures behavior']"
50,5,Fang-Chi Yang,"Department of Cognitive, Linguistic, and Psychological Sciences","The posterior parietal cortex (PPC) in rodents and primates is important for visuospatial attention. The human PPC shows functional differentiation such that dorsal areas are implicated in top-down, controlled attention, and ventral areas are implicated in bottom-up, stimulus driven attention. Whether the rat PPC also shows functional differentiation is unknown. In the present study, we provided evidence from in vivo electrophysiology to address this open question. We simultaneously recorded neuronal activity in dorsal and ventral PPC as rats performed a visuospatial attention task that engaged in both bottom-up and top-down attention. Our previous study provided evidence dorsal PPC is involved in multiple cognitive processes of the translation of perception to action (Yang, Jacobson, & Burwell, 2017). In this study, we showed that ventral PPC cells responded to stimulus onset more rapidly than dorsal PPC cells suggesting engagement in stimulus-driven bottom-up attention. The slower time course of neuronal response latency in the dorsal PPC might reflect top-down controlled attention to guide the appropriate behavior selection. These data suggest that the rat PPC, like the primate PPC, is functionally differentiated such that the dorsal PPC is more important for controlled attention and ventral PPC is more important for stimulus driven attention. ","['dorsal ppc might reflect topdown controlled attention', 'rat ppc also shows functional differentiation', 'human ppc shows functional differentiation', 'previous study provided evidence dorsal ppc', 'dorsal ppc cells suggesting engagement']"
51,6,Brenda Rubenstein,Chemistry,"(Warning: Highly Underbaked, but Likely Correct!) Over the past few years, the Brown Molecular Informatics team has been developing new ways of storing information in and computing with small molecules. While our team has clearly demonstrated how to store information in thousands of small molecules by using the presence or absence of molecules in mixtures to encode bits (see Arcadia et al., Nature Communications (2020) and Kennedy et al., PLoS One (2020)), it is less clear to us - as well as the much larger community - how to compute using molecules. One way to perform chemical computation is to use chemical reaction networks (CRNs), which consist of molecules interconnected with each other by chemical reactions with different rate constants. In principle, a sufficiently large reaction network with a variety of rate constants should be Turing complete, but no one has yet mapped out which reaction networks correspond to which computations and how to build more complex computations modularly. 
Here, I will describe an idea to learn these mappings via machine learning. Given a function one would like the network to compute that can be used as a cost function, the rate constants and structures of the networks can be learned. It should be noted that these reaction networks can be translated into sets of coupled ordinary differential equations. I would therefore love to obtain advice from data scientists and mathematicians who may have tried to perform similar mappings in other contexts before. Ultimately, this learning will be used to identify real organic reactions that can be used to perform valuable computations. ","['encode bits see arcadia et al nature communications', 'kennedy et al plos one', 'mappings via machine learning given', 'use chemical reaction networks crns', 'compute using molecules one way']"
52,6,Ehsan Barati,Chemistry,"Quantum state transfer (QST) of a qubit over Hubbard chains is investigated. The quantum state is initially prepared in an ordinary node and it is transferred to the corresponding antipode in the chains, by employing stratification and spectral distribution techniques in graph theory. An analytical expression for fidelity of QST, different for even and odd numbers of atomic sites in the chain N, is presented for an arbitrary length of the chains (N). It is revealed that the fidelity decreases monotonically with increasing N making a perfect state transfer of qubits over Hubbard chains of the length N = 2, 3 but optimal transfer for N > 3. The presented explicit expression for fidelity provides the necessary conditions for QST of entangled quantum states over Hubbard chains in terms of the system parameters, namely the exchange interaction and the time evolution of the transfer. ","['quantum state transfer qst', 'system parameters namely', 'spectral distribution techniques', 'entangled quantum states', 'perfect state transfer']"
53,6,Haley Keglovits,CLPS,"The human brain is capable of incredible flexibility, but what gives it this power is still unknown. One possible mechanism is the way neuron populations organize the information they carry. Specifically, the dimensionality of the neural representational of task information is hypothesized to play a crucial role in enabling this flexibility. While some strides have been made to measure dimensionality in monkeys using single cell recording, alternative methods will be necessary to non-invasively do so in humans. In this project, I seek to quantify how dimensionality estimates from fMRI BOLD data made with a published method (Ahlheim & Love 2018) are affected by the amount of data available for estimation. I use one large set of human fMRI data to investigate how estimated dimensionality changes depending on the amount of data included. The analyses show that both specific brain regions and the dimensionality estimate itself (high or low) affect how stable the estimates are, but that these relationships may be regular. How this analysis will be expanded to other subjects and simulated data will be discussed.","['monkeys using single cell recording alternative methods', 'still unknown one possible mechanism', 'use one large set', 'way neuron populations organize', 'published method ahlheim love']"
54,6,Fumeng Yang,Computer Science at Brown,"One core problem for data visualization is to understand how humans perceive visualizations. Recent advances in investigating visual comparison tasks (e.g., selecting the bigger mean between two bar charts, selecting the higher correlation between two scatterplots)  show evidence that humans are using visual proxies for such tasks. However, the current modeling techniques (e.g., logistic regression, mixed-effects models, as well as Bayesian approaches to these) for these human judgments are still preliminary and imprecise. The recent advances from the fields of machine learning and computer vision show the potentials for a neural network to extract visual relation and perform graphical perception. As such, we propose to use deep neural networks to model, describe, and predict human judgments for visual comparison tasks. The proposed work has three components: first, we wish to use neural networks for visual comparison tasks to understand if a neural network can perform visual comparison; second, we wish to train neural networks to describe and predict human judgments in visual comparison tasks; third, we wish to understand the internal representations of the trained neural works to understand human perception.","['current modeling techniques eg logistic regression mixedeffects models', 'investigating visual comparison tasks eg selecting', 'humans perceive visualizations recent advances', 'two bar charts selecting', 'visual comparison tasks third']"
55,6,Apoorva Bhandarii,CLPS,"The prefrontal cortex (PFC) is necessary for flexible control of behavior. While PFC neural activity encodes a variety of task-relevant variables, the format or geometry of this code and its relationship to flexibility remain obscure. An important property of a representational geometry is dimensionality, which balances a critical trade-off between separability and generalizability. High-dimensional representations of task variables may support flexible control by providing an expressive basis set for implementing arbitrary tasks. Lower-dimensional representations may afford robustness against noise and generalize to similar tasks. In highly trained macaques, lateral PFC representations of task variables approach maximum possible dimensionality, and predict success on the task. It is unclear whether this finding will generalize to humans, who are able to perform a diverse array of novel tasks with far less training. Probing representational geometry in human PFC has been hampered by the relatively low reliability of fMRI BOLD activity patterns. To circumvent this obstacle, we develop an alternate fMRI adaptation approach which leverages neuron-level repetition suppression effects to estimate dimensionality. We show that our approach can recover ground-truth dimensionality from simulated fMRI data. Finally, using empirical data, we employ both fMRI adaptation and pattern-analysis methods to triangulate the dimensionality of PFC representations. ","['implementing arbitrary tasks lowerdimensional representations may afford robustness', 'simulated fmri data finally using empirical data', 'highly trained macaques lateral pfc representations', 'far less training probing representational geometry', 'task variables may support flexible control']"
56,6,Mathieu Chalvidal,Artificial and Natural Intelligence Toulouse Institute/Carney Institute for Brain Science,"The intriguing connections recently established between neural networks and dynamical systems have invited deep learning researchers to tap into the well-explored principles of differential calculus. Notably, the adjoint sensitivity method used in neural ordinary differential equations (Neural ODEs) has cast the training of neural networks as a control problem in which neural modules operate as continuous-time homeomorphic transformations of features. Typically, these methods optimize a single set of parameters governing the dynamical system for the whole data set, forcing the network to learn complex transformations that are functionally limited and computationally heavy. Instead, we propose learning a data-conditioned distribution of \emph{optimal controls} over the network dynamics, emulating a form of input-dependent fast neural plasticity. We describe a general method for training such models as well as convergence proofs assuming mild hypotheses about the ODEs and show empirically that this method leads to simpler dynamics and reduces the computational cost of Neural ODEs. We evaluate this approach for unsupervised image representation learning; our new ``functional'' auto-encoding model with ODEs,  AutoencODE, achieves state-of-the-art image reconstruction quality on CIFAR-10, and exhibits substantial improvements in unsupervised classification over existing auto-encoding models.","['odes autoencode achieves stateoftheart image reconstruction quality', 'neural ordinary differential equations neural odes', 'convergence proofs assuming mild hypotheses', 'intriguing connections recently established', 'unsupervised image representation learning']"
57,6,Seth Akers-Campbell,Neuroscience,"Several times per second, humans and other primates make rapid eye movements (saccades) that redirect their gaze towards objects of interest. Psychophysical evidence suggests that saccades not only move the eyes, but their associated motor signals significantly modulate image processing and subsequently visual perception. However, the neural basis of this perceptual modulation is poorly understood. To investigate this link, we used multi-electrode arrays to record from a population of visual neurons in macaques while they performed a psychophysical task. Stimuli were presented in the neurons’ receptive fields immediately at the start of fixation, as in natural vision, after either a saccade or a simulated saccade (without the associated motor signal). At fixation onset, we find that macaque sensitivity to low spatial frequency stimuli is reduced, consistent with human data, and sensitivity to higher spatial frequencies is simultaneously enhanced. Importantly, the changes in neural activity correlate with the changes in perceptual sensitivity. Furthermore, we leveraged our parallel recordings during decision making to measure correlated variability within the observed population, enabling us to estimate the perceptual contributions of individual neurons. We find that suppression or enhancement of neural activity due to saccades is strongest in neurons which best predict the animal’s perceptual decisions.","['associated motor signals significantly modulate image processing', 'primates make rapid eye movements saccades', 'several times per second humans', 'neurons ’ receptive fields immediately', 'measure correlated variability within']"
58,6,Meredith Miles,Brown EEB,"	Communication is a fundamental behavior; animals use it to choose a mate, exchange information, navigate their environment, and more. In social vertebrates like birds and mammals, communication traits are fast-evolving and can even reroute how fundamental ecological and morphological traits evolve. Here I show communication changes over millions of years in the context of competition and mate choice. These studies use novel techniques to explore when and why courtship displays change their complexity by gaining or losing component behaviors. More importantly, gaining insight into the broad processes that shape animal communication (including human communication) may prove critical to advancing interdisciplinary work on humanity’s greatest challenges for the 21st century (e.g. dismantling systemic racism, combatting misinformation).  After discussing work presented in hundreds of bird species, I showcase the ways that behavior can evolve rapidly to reshape an animal’s evolutionary context. Along the way I highlight how our collective understanding of evolution continues to change— and how the scholarly community might use this understanding to create change from within the Ivory Tower, and beyond it.","['shape animal communication including human communication may prove critical', 'st century eg dismantling systemic racism combatting misinformation', 'studies use novel techniques', 'social vertebrates like birds', 'scholarly community might use']"
59,7,matt nassar,neuroscience,"One major challenge for AI is that, while deep neural networks are capable of achieving human level performance on a wide variety of tasks, they require an unreasonable number of learning trials. This issue has stimulated an interest in the inductive biases that humans and animals employ to constrain learning in complex natural environments. While the neural mechanisms used to implement inductive biases could be informative for both improving AI and providing a better mechanistic understanding of learning, these neural underpinnings remain elusive. Here we explore the possibility that stimulus-independent pairwise correlations between neurons, or so-called noise correlations, might reflect inductive biases used to constrain learning to specific task-relevant dimensions. We test this idea with a neural network model of a two-alternative forced-choice perceptual discrimination task in which the correlation among similarly tuned units can be manipulated independently of the overall population signal-to-noise ratio. Higher noise correlations among similarly tuned units, which emerge naturally through Hebbian learning, led to faster and more robust learning through weight adjustments that favored homogenous weights assigned to neurons within a functionally similar pool. These results suggest that noise correlations may serve to reduce the dimensionality of learning thereby making it more rapid and robust. ","['overall population signaltonoise ratio higher noise correlations among similarly tuned units', 'socalled noise correlations might reflect inductive biases used', 'correlation among similarly tuned units', 'twoalternative forcedchoice perceptual discrimination task', 'noise correlations may serve']"
60,7,Guillaume Pagnier,Neuroscience,"Parkinson’s disease (PD) is a common neurodegenerative disease affecting 1% of the elderly population. While the most common treatment is to administer dopaminergic (DA) medication, deep brain stimulation (DBS) is also used. DBS involves neurosurgeons implanting an electrode, usually in the subthalamic nucleus (STN) of human PD patients. High frequency (<130 hz) STN DBS improves motor symptoms, but STN DBS PD patients sometimes start exhibiting impulsive behavior, similar to the behavior of some PD patients on DA meds. Computational models of basal ganglia function suggest DBS and DA medication increase impulsivity via two distinct mechanisms: 1)  By interfering with STN activity, DBS reduces the decision threshold in an evidence accumulation framework, modeled with the drift diffusion model; 2) By altering striatal DA levels, DBS distorts the influence of benefits vs costs on decision making. I hope to evaluate whether low vs high frequency stimulation in different STN contact locations (dorsal vs ventral) as well as DA (DA ON and DA OFF) can have differential effects on decision threshold or cost-benefit decision making in a physical effort-discounting task. Here, I present some pilot data comparing PD patients and healthy controls' behavior to clarify DA and PD's effects on cost/benefit decision making.","['human pd patients high frequency hz stn dbs improves motor symptoms', 'stn dbs pd patients sometimes start exhibiting impulsive behavior similar', 'da medication increase impulsivity via two distinct mechanisms', 'administer dopaminergic da medication deep brain stimulation dbs', 'evaluate whether low vs high frequency stimulation']"
61,7,Jacob Rosenstein,Engineering,"Molecular information systems have the potential to store data at dramatically higher density than existing electronic media. Many valuable experimental demonstrations of this idea have used DNA, but nature also uses many other types of molecules and chemical networks to preserve, process, and transmit information. In this short talk I will introduce some of the concepts of chemical data representations, discuss a few of their implications for synthetic non-electronic data systems, and present examples from our recent collaborative research in this area. ","['existing electronic media many valuable experimental demonstrations', 'nature also uses many', 'synthetic nonelectronic data systems', 'chemical data representations discuss', 'recent collaborative research']"
62,7,Anastacia Kudinova,Psychiatry and Human Behavior,"Aligning with the NIMH’s Prioritized Agenda for Suicide Prevention Research, this new project seeks to advance what is known about the brain/behavior mechanisms underlying self-critical rumination ─ persistent negative-self-evaluation ─ and self-reassurance ─ providing compassion to self. The central hypothesis is that circuit alterations in the dorsolateral and dorsomedial prefrontal cortex, dorsal anterior cingulate, and insula underlying self-critical rumination and self-reassurance are associated with increased suicidal thoughts and behavior (STB) in adolescents. Our central methodology is to examine self-critical rumination and self-reassurance using task-dependent and task-independent functional magnetic resonance imaging (fMRI) and ecological momentary assessment (EMA) in 90 12-15 year-old teens recruited on the range of STB. The research goals are: (i) to test the associations between in vivo self-critical rumination, self-reassurance, and STB; (ii) identify neural mechanisms underlying self-critical rumination and self-reassurance; (iii)¬¬ integrate the findings from the scanner with STB assessed in adolescents’ real world environment. The focus on identifying construct-specific neural mechanisms, a trans-diagnostic sample of teenagers, and integration of imaging and EMA techniques is innovative. This project is significant, because identifying specific neural mechanisms underlying the interplay between self-critical rumination, self-reassurance, and STB can contribute to development of novel, mechanistically-informed interventions. ","['brainbehavior mechanisms underlying selfcritical rumination ─ persistent negativeselfevaluation ─', 'stb ii identify neural mechanisms underlying selfcritical rumination', 'dorsomedial prefrontal cortex dorsal anterior cingulate', 'taskindependent functional magnetic resonance imaging fmri', 'identifying specific neural mechanisms underlying']"
63,7,"Taylor A. Burke, Ph.D.",DPHB,"A history of prior self-injury is one of the strongest predictors of future suicidal behavior, and evidence suggests that the more severe such prior self-injurious behaviors are, the greater the risk for future self-injury. Importantly, however, our current means of assessing severity of prior self-injury is almost entirely reliant on self-report, despite the fact that self-injury frequently leaves tangible physical markings. Leveraging computer vision to automatically assess images of tissue damage has the potential to obviate reliance on subjective patient report of self-injury severity characteristics. My Lightning Talk will provide a brief overview of a cross-disciplinary grant submission designed to employ deep convolutional neural networks to detect severity indices of self-injury and to examine their accuracy in predicting short-term prospective suicide risk. This proof-of-concept study will set the stage to determine the feasibility of pursuing our long-term goal of integrating this technology into psychiatric care entry-points (primary care, emergency departments, inpatient units) to assess whether it can augment current risk assessment models. ","['psychiatric care entrypoints primary care emergency departments inpatient units', 'selfinjury frequently leaves tangible physical markings leveraging computer vision', 'employ deep convolutional neural networks', 'predicting shortterm prospective suicide risk', 'augment current risk assessment models']"
64,7,Andrew Delworth,Brown University,"Bone tumors, a common cause of cancer-related deaths in people under the age of 20, can be particularly challenging to classify on imaging because of tumor heterogeneity, the rarity with which they are encountered, and potential for confusion with non-cancer diagnosis (e.g., infection). Magnetic resonance imaging is a sensitive imaging modality for characterization of bone lesions, but suffers from poor specificity. We are developing a novel deep neural network model that integrates features from multi-sequence 3D MR data and patient clinical data to differentiate benign from malignant bone lesions with increased specificity while maintaining or improving sensitivity and accuracy. While the model is still being finalized, early results show it outperforming radiologists in accuracy, sensitivity, and specificity. The final model will be integrated into a previously developed software interface for connecting AI systems into the PACS at Rhode Island Hospital, as a preliminary step towards clinical implementation. Our work has the potential to contribute to the decrease in morbidity and mortality through improved diagnosis of malignancies and lower rate of unnecessary biopsies of benign lesions due to uncertain results from imaging.","['noncancer diagnosis eg infection magnetic resonance imaging', 'preliminary step towards clinical implementation', 'novel deep neural network model', 'previously developed software interface', 'finalized early results show']"
65,7,Shane Lee,Department of Neuroscience,"Prediction of motor error using intracranial neural recordings in patients with Parkinson's Disease

Parkinson's disease (PD) is a neurological disorder in which substantial motor impairment is often observed. For severe cases, deep brain stimulation (DBS) of the subthalamic nucleus can be an effective treatment, particularly alleviating motor symptoms such as tremor or bradykinesia. However, present clinical evaluation of PD uses qualitative assessments to rate only the worst of symptoms, and standard DBS therapy is static. In contrast, PD symptoms are observed to change in severity on a rapid basis. Here, we use support vector classification of motor performance on a joystick-based target tracking task to quantify motor error severity, observing that patients with PD are distinguishable for controls on a seconds timescale, and we define a continuous motor error score from the distance orthogonal to the classification hyperplane. We use neural recordings from subthalamic nucleus and sensorimotor cortex to predict the motor error score during the task using convolutional networks on raw recordings and feedforward networks on spectral estimates. Our ability to decode motor error from neural recordings may be useful in developing adaptive, closed loop DBS to modulate stimulation on a moment-to-moment basis based on patient-specific neural biomarkers.","['severe cases deep brain stimulation dbs', 'effective treatment particularly alleviating motor symptoms', 'motor error using intracranial neural recordings', 'bradykinesia however present clinical evaluation', 'developing adaptive closed loop dbs']"
66,7,Camillo Saueressig,CCMB,"Manual evaluation of medical images, such as MRI scans of brain tumors, requires years of training, is time-consuming, and is often subject to inter-annotator variation. Automatic segmentation of medical images is a long-standing challenge which seeks to alleviate these issues, with great potential benefit for both radiologists and patients. In the past few years, variations of Convolutional Neural Networks (CNNs) have established themselves as the state-of-the-art methodology for this task. Recently, Graph Neural Networks (GNNs) have gained considerable attention in the Deep Learning community. GNNs exploit the structural information present in graph data by aggregating information over connected nodes to output predictions on either the node or graph level. In this project, we propose a GNN-based approach to brain MRI glioma segmentation. We model brain MRI scans as graphs composed of connected brain regions, and train several GNN variants to classify graph nodes, i.e. brain regions, as tumorous or healthy. Our preliminary results show that graph-based methods are potentially competitive with state-of-the-art CNN methods. We also observe that GNNs which employ a self-attention mechanism, e.g. Graph Attention Networks (GATs), tend to outperform convolution-based graph networks (GCNs) at this task.","['selfattention mechanism eg graph attention networks gats tend', 'classify graph nodes ie brain regions', 'task recently graph neural networks gnns', 'outperform convolutionbased graph networks gcns', 'deep learning community gnns exploit']"
67,8,Aimen Zerroug,CLPS - ANITI,"Title: A recurrent neural circuit model for color constancy

Aimen Zerroug, Drew Linsley, and Thomas Serre

Carney Institute for Brain Science, Brown University

The neural circuits that give rise to color constancy, the ability to perceive surface color under a changing illumination, are still poorly understood. While there is growing evidence of complementary roles for both classical (CRF) and extra-classical receptive fields (eCRF) in biological color constancy, Land’s celebrated Retinex algorithm has remained the standard for the past several decades even though it makes no clear distinction between CRF and eCRF. 

We investigated the roles of CRFs and eCRFs in color constancy by creating a differentiable approximation of the neural circuit model of Mely et al (2018), which leveraged constraints from physiology and anatomy to simulate contextual illusions spanning visual modalities. When trained for color constancy on computer vision benchmarks, a single layer of this network was competitive with much larger state-of-the-art models, while also exhibiting illusory induction effects that are consistent with human psychophysics data. Lesioning model eCRFs significantly decreased performance and destroyed induction. Furthermore, correcting model sensitivity to color illusions worsened color constancy, indicating that they represent features — not bugs — of neural circuits optimized for color constancy. Our study offers direct evidence for recurrent circuits’ contribution to color constancy, revising extant theory on the computations involved in color perception.","['human psychophysics data lesioning model ecrfs significantly decreased performance', 'simulate contextual illusions spanning visual modalities', 'destroyed induction furthermore correcting model sensitivity', 'color constancy aimen zerroug drew linsley', 'color illusions worsened color constancy indicating']"
68,8,Sarah Thomas PhD,Psychiatry and Human Behavior,"Cannabis use (CU) initiated in adolescence is associated with substantial consequences, from cognitive decline to addiction. Adolescents’ greater vulnerability to CU effects may be due to the high concentrations of endogenous cannabinoid receptors in regions developing during adolescence (e.g., prefrontal and striatal). While CU may disrupt normal processes of adolescent brain development, relatively little is known about how adolescent CU is associated with brain/behavior mechanisms of reward-related decision-making. Advancing knowledge of these processes may explain why adolescent-onset CU is linked to functional impairments and higher rates of problematic substance use. This project is a component of a mentored award from Brown’s Advance-CTR and a potential K23 award. The central hypothesis to be tested is that CU in the context of adolescent brain development is linked to frontostriatal alterations and impaired reward-related decision-making that will vary as a function of CU exposure. Adolescents (equal groups who are engaged in CU and control adolescents) will be characterized on CU exposure and will undergo an MRI while completing a reward-related decision-making task. Behavioral and neural data from the decision-making task will be integrated in a computational psychiatry model to test whether and how latent decision-making components differ between adolescents with and without CU.","['addiction adolescents ’ greater vulnerability', 'adolescent brain development relatively little', 'cu may disrupt normal processes', 'cu exposure adolescents equal groups', 'latent decisionmaking components differ']"
69,8,Adam Berkley,Computer Science,"In recent years, extensive research has been conducted on improving brain tumor segmentation models. Hundreds of papers have been published on the effectiveness of different or new models on this problem, with predictive ability reaching that of trained experts. The major proposed application of these models is preliminary screening of patients, which would involve using a pre-trained model to segment images across multiple institutions. It wouldn’t be feasible for each institution to have their own model trained, as most don’t have a dataset of patients extensive enough for training. However, most current models are trained and tested on datasets from a single institution (usually the MICCAI BraTS dataset from UPenn). Due to differences in the imaging techniques deployed by the hospitals and in the MRI machines used, performance of models on different institution’s datasets may vary greatly. The proposed study is to explore the cross-domain ability of different types of models to see if they would be effective in real world applications.","['improving brain tumor segmentation models hundreds', 'segment images across multiple institutions', 'mri machines used performance', 'recent years extensive research', 'datasets may vary greatly']"
70,8,Paul Stey,Center for Computation and Visualization,"It has been nearly 15 years since Ioannidis published his landmark paper ""Why Most Published Research Findings Are False"". In this paper, Ioannidis describes the many ways in which scientific research can be (intentionally or otherwise) manipulated to produce a statistically significant result (e.g., ""p-hacking"", hypothesizing after the fact, etc.). This paper helped galvanize the movement for reproducibility in scientific research. 
Absent from Ioannidis original paper was a discussion of computational tools and methods, and how their use or misuse can contribute to the challenges of reproducing scientific findings. 
In this talk we provide and introduction to a number of tools aimed at ensuring the reproducibility of our research. In particular, we discuss the use of Docker ""containers"" for conducting and reproducing workflows in the computational sciences. The talk will provide a brief overview of Docker and container technologies in general. We also address questions regarding when to use containers; what problems they solve; and how to share and collaborate with others using containers. This talk will serve as a highly applied introduction, and thus, no prior knowledge of Docker or containers is assumed.","['statistically significant result eg phacking hypothesizing', 'nearly years since ioannidis published', 'also address questions regarding', 'paper ioannidis describes', 'ioannidis original paper']"
71,8,Shalin Patel,Applied Math/CCMB,"It has been shown that genes often interact in complex and ways that are best defined in terms of graphical terms. For instance, Gene Regulatory Networks (GRNs) have long been an area of study with landmark algorithms like GENIE3 delivering high quality networks that describe the interaction between genes in human cell lines, usually, with respect to gene expression. Along a similar vein, deep learning techniques like CNNs and RNNs have been introduced to the field in recent years to help enhance gene expression prediction. Unfortunately, these techniques ignore the graphical interaction mechanism that underlies cell processes. As such, this work aims to bridge the two areas of study by utilizing recently innovated methods in Graph Neural Networks and Graph Convolutional Networks to enhance the ability of Deep Learning methods with respect to the complex context of genomics. This work shows that in the realm of gene expression prediction and classification, the novel approach of utilizing the GRN graph structure within the GCN framework on epigenetic data is able to enhance prediction accuracy for multiple cell lines. In fact, the GCN method is able to outperform the state-of-the-art across all cell lines that were tested and deliver model interpretability.","['landmark algorithms like genie delivering high quality networks', 'similar vein deep learning techniques like cnns', 'help enhance gene expression prediction unfortunately', 'instance gene regulatory networks grns', 'grn graph structure within']"
72,8,Wasita Mahaphanit,CLPS,"Obsessive compulsive disorder (OCD) is a psychiatric disorder marked by recurrent, intrusive thoughts (i.e., obsessions) that cause repetitive, ritualistic behaviors (i.e., compulsions; American Psychological Association, 2013), and people suffering from OCD report experiencing pathological doubt (i.e., the lack of one’s confidence in cognitive faculties to reach a decision) and excessive uncertainty (Dar, 2004). Despite its morbidity and prevalence, the computational mechanisms that give rise to symptoms, and their neural substrates, remain relatively underdefined. Using computational modeling in a novel incentivized information-sampling task, we will test whether information seeking behavior is sensitive to reward value and/or uncertainty (i.e., level of evidence), and the degree to which OCD symptoms correlate with either of these constructs (e.g., Does information seeking behavior only correlate with OCD symptoms when it is insensitive to uncertainty? Does this parallel the reassurance compulsions in OCD such as excessive hand washing?). Preliminary data suggest healthy controls (HCs) are sensitive to both uncertainty and value, and ongoing work seeks to uncover sensitivities specific to OCD. We hope this work will lead to behavioral biomarkers of OCD, to ultimately inform neural markers of maladaptive brain states for use in developing closed-loop, adaptive deep brain stimulation (aDBS) treatments for treatment-refractory OCD.","['excessive hand washing preliminary data suggest healthy controls hcs', 'cause repetitive ritualistic behaviors ie compulsions american psychological association', 'developing closedloop adaptive deep brain stimulation adbs treatments', 'neural substrates remain relatively underdefined using computational modeling', 'ocd report experiencing pathological doubt ie']"
73,8,Daniel Smits,Brown Computer Science and CLPS depts,"Humans exceed at understanding unspoken meaning. For example, imagine I am hosting a house party and serving drinks. If I told you ""I only have milk,"" does that tell you that I don’t have any wine? What about ketchup? Can computational models generate human-like judgments to these questions? To do so, both traditional and connectionist models of implicature rely on sets of alternatives. There is extensive debate over the mechanisms by which we compute implicatures. Nevertheless, we know very little about which alternatives are inputs to this computation and how these alternatives are generated. We attempt to bridge this gap by addressing a series of questions. First: how are alternatives structured? Second: which alternatives are considered when computing an implicature? Third: which computational model best predicts the set of alternatives? Answering these questions will provide insights into the mechanisms which derive pragmatic inferences and will allow us to develop more contextually sensitive linguistic AI.","['computational models generate humanlike judgments', 'computational model best predicts', 'contextually sensitive linguistic ai', 'understanding unspoken meaning', 'derive pragmatic inferences']"
74,8,Emily Levin,CLPS,"Visual working memory (VWM) is a capacity-limited system that requires control processes to manage what information enters memory (“input gating”) and to select what information guides a response (“output gating”). Gating mechanisms are important because they mediate the balance between the predicted utility of an item and our limited memory capacity. For example, input gating proactively updates information to memory that has been deemed 100% relevant to the task (high priority) and filters information that is irrelevant. Conversely, output gating manages the contents of VWM when relevance is known only after encoding. That is, when items must be remembered even though their relevance is uncertain. The present experiment investigated how information content in VWM differed for items that were input gated with 100% certainty, versus for items that were only potentially relevant. Participants were scanned on a VWM orientation gating task across two fMRI sessions. We used a Bayesian approach to compute the full probability distribution of the stimuli given the BOLD data during input gating and output gating events. This approach allowed us to reconstruct the orientations that participants saw in the scanner and estimate both the precision and accuracy of remembered orientations. We observed higher accuracy for items input gated with 100% certainty relative to 50% certainty (i.e., in input gating versus output gating events). However, precision did not appear to differ. These results suggest that the accuracy of information held in VWM tracks priority, but precision does not. ","['vwm orientation gating task across two fmri sessions', 'response “ output gating ” gating mechanisms', 'input gating versus output gating events however precision', 'information enters memory “ input gating ”', 'example input gating proactively updates information']"
75,9,Drew Linsley,CLPS and Carney,"According to Marr's ""tri-level hypothesis"", there are three distinct levels of analysis needed to understand complex systems like the brain. (1) What problems does the system solve (computational)? (2) How does it solve these problems (algorithmic)? (3) What is the physical instantiation of the system's computations (implementation)? This framework has dominated systems and computational neuroscience research over the past 20 years, providing much needed theoretical context to brain sciences, while also siloing progress at each level of analysis. For instance, recurrent neural mechanisms, such as those that give rise to so-called classical vs. extra classical receptive fields (CRF vs. eCRF), are well studied at the level of their “implementation” via feedforward/recurrent inhibition/excitation. However, it is still unclear how these neural mechanisms give rise to network level phenomena at algorithmic or computational levels of analysis. Here, we develop an approach for understanding recurrent vision at all three of Marr’s levels of analysis. We develop a recurrent visual model with circuits inspired by those in primate visual cortex and optimize it for object segmentation in natural images. This model learns algorithms for object segmentation which compute low-level gestalt and exhibit contextual illusions. At the same time, the model’s responses to orientation stimuli explain CRF and eCRF effects observed in primate visual cortex. Through lesion studies, we demonstrate the relative importance of phenomena at implementational and algorithmic levels for performance at the computational level. Our approach shows that by unifying Marr’s levels of analysis we can distinguish neural epiphenomena from behaviorally relevant computations, while also identifying those mechanisms which are learned vs. those which must be induced through other means.","['socalled classical vs extra classical receptive fields crf vs ecrf', '“ implementation ” via feedforwardrecurrent inhibitionexcitation however', 'past years providing much needed theoretical context', 'orientation stimuli explain crf', 'understand complex systems like']"
76,9,Jeremy Bigness,Center for Computational Molecular Biology (CCMB),"Although biologists can perform time-series RNA-seq measurements at discrete points, the temporal resolution of such experiments is necessarily limited due to the need to isolate RNA from the cells at each step. This missing information hampers the identification of causal gene regulatory interactions as well as groups of coregulated genes. In addition, it prevents the characterization of the kinetics of transcriptional responses. Imaging studies with high temporal resolution have attempted to fill this void, but such studies label single molecules and cannot measure gene expression across the entire genome simultaneously. To overcome these limitations, I will construct a conditional generative adversarial neural network that infers time series gene expression trajectories. Conditional generative adversarial neural networks are comprised of two distinct neural networks: a generator and a discriminator. The generator network produces an output based upon the conditional inputs as well as a random noise vector, seeking to produce an output that the discriminator network classifies as authentic based off prior training examples. In the past few years, some studies have explored the potential of generative adversarial networks to impute missing values in time series data. However, these methods have not been applied in the context of gene expression.","['infers time series gene expression trajectories conditional generative adversarial neural networks', 'conditional generative adversarial neural network', 'cannot measure gene expression across', 'time series data however', 'two distinct neural networks']"
77,9,Josephine Kalshoven,"Orthopedics, Center for Biomedical Engineering","The trapeziometacarpal (TMC) joint sits in the wrist at the base of the thumb and enables proper thumb movement. The kinematics of this joint, particularly the in-vivo loading of the trapezium bone constituent, are poorly understood. Current estimations of trapezial loads are derived solely from musculoskeletal models. This limited knowledge inhibits the development of durable TMC implants to replace arthritic joints. We seek to develop the first instrumented replacement trapezium, which uses internal strain gauges to determine the 6 DOF in-vivo loads experienced by the trapezium bone. We are currently developing software that converts strain gauge output to an estimation of the load applied to the articular surface of the device. We use a least-squares estimation approach in MATLAB to establish a “calibration matrix” relationship between paired matrices of load and strain data generated via elastic beam theory analytical models. This method has yielded load estimates from test strain data (+/-5% random error) with average relative errors typically <1%. More recent exploration of alternative techniques utilizing machine learning (multiple linear regression and neural networks) show promising results with even lower load estimation error.  ","['strain data generated via elastic beam theory analytical models', 'alternative techniques utilizing machine learning multiple linear regression', 'test strain data random error', '“ calibration matrix ” relationship', 'neural networks show promising results']"
78,9,Jamie Catalano,Molecular Pharmacology and Physiology,"Understanding alcohol’s complex effects on reward circuits in the brain is critical for the development of better biologically informed therapies for alcohol use disorder. Recent advances in neurogenetics paired with the ability of flies to exhibit complex behaviors, such as associative learning and sensorimotor integration, have highlighted Drosophila melanogaster as an exciting model to study the effects of alcohol on the brain. However, methods for assessing latent behaviors such as motivation and aversion are lacking in the Drosophila field. To address this methodological gap, we have developed a runway based operant conditioning assay for investigating the motivational drive for vaporizable stimuli like alcohol. Our results suggest that Drosophila initially demonstrate avoidance behaviors, but then switch to motivated seeking behaviors for alcohol. Computer vision and machine learning software provide several measurable features of fly behavior that are used to provide a high-resolution view of aversive and motivated behaviors in this model. Future studies will assess the necessity and sufficiency of specific neuronal circuits in alcohol mediated seeking and avoidance. ","['machine learning software provide several measurable features', 'runway based operant conditioning assay', 'alcohol use disorder recent advances', 'drosophila initially demonstrate avoidance behaviors', 'better biologically informed therapies']"
79,9,Joseph Heffner,CLPS,"People make decisions based on deviations from expected outcomes (i.e., prediction errors). Past work has focused on reward prediction errors, largely ignoring violations of expected emotional experiences (i.e., emotion prediction errors). We leverage a new method to measure real-time fluctuations in emotion as people decide to punish or help others. Across three studies (N=789), we reveal that emotion and reward have independent and dissociable contributions to choice, such that emotion prediction errors exert the strongest impact on deciding to punish or help another. We additionally find that these decisions can be decoded from their emotional responses as early as 430ms, suggesting emotions swiftly influence choice. Finally, individuals with depression exhibit selective impairments in using emotion—but not reward—prediction errors. By demonstrating the power of emotion prediction errors in guiding social behaviors, these findings challenge standard decision-making models that have focused solely on reward.","['ms suggesting emotions swiftly influence choice finally individuals', 'expected outcomes ie prediction errors past work', 'expected emotional experiences ie emotion prediction errors', 'help others across three studies n', 'reward prediction errors largely ignoring violations']"
80,9,Bjorn Burkle,Physics,"Since the discovery of the Higgs Boson in 2012, studies have been continuously carried out to fully measure the particle’s properties. However, we are now at the point where the “low hanging fruit” have been picked and further studies of the Higgs Boson require the use of advanced analysis methods. One such study currently being performed by the CMS collaboration is the search for a Higgs Boson decaying to two charm quarks. Identifying the presence of hadronizing charm quarks at the Large Hadron Collider is a very difficult task that requires the use of specialized neural networks. In this talk, I will give an overview of the DeepJet neural network and how it is used to identify the presence of charm quarks in a particle collision. I will then describe how we account for the differences between the Monte Carlo simulations used to train the network, and the actual data used in our analysis.","['“ low hanging fruit ”', 'monte carlo simulations used', 'advanced analysis methods one', 'two charm quarks identifying', 'specialized neural networks']"
81,9,Tom Sgouros,Computer Science/Brown,"Neural networks, originally inspired by biology, took a big step last year when researchers showed it is feasible to obtain decent machine learning results on image datasets using a network of randomly connected nodes.

Preliminary modeling results show that simpler tasks are also possible.  It is feasible, for example, to assemble discriminators and comparators using random acyclical connections between nodes that individually do neither of those things.  The results are robust to significant degradation of node performance.  Adding feedback connections introduces a time base and allows the creation of signal amplifiers and filters.  These observations are not tied specifically to spike-chain analysis, but are general results involving non-linear computations in the context of complex networks.

Relating node function and the density and pattern of connections could aid the development of new computing paradigms, such as quantum computing, as well as provide insights into both the ontogenetic and phylogenetic development of actual nervous systems.
","['randomly connected nodes preliminary modeling results show', 'node performance adding feedback connections introduces', 'complex networks relating node function', 'obtain decent machine learning results', 'general results involving nonlinear computations']"
82,9,Minju Jung,CLPS,"One of the promising approaches to enhance recovery of spinal cord injury is epidural electrical stimulation (EES) of the spinal cord that facilitates a broad range of motor behaviors. However, which EES facilitates motor control is unknown due to the lack of understanding on the spinal cord mechanism. Although the computational models of the spinal cord have been proposed, the experimenters should tune parameters, such as synaptic weights, to match experimental measurements. According to the universal approximation theorem, an artificial neural network with enough hidden units can approximate arbitrarily complex input to output mappings. This means that, we could use a deep feedforward neural network or a recurrent neural network to model the spinal cord without requiring hand tuning of parameters. Furthermore, we propose a new neural network, called DeepSpine, constrained by the anatomy and physiology of the spinal cord. We hypothesize that DeepSpine will show better sample efficiency than black-box neural networks because of an inbuilt architectural bias. Using sheep data, we present initial results demonstrating that deep neural networks are able to learn the complex mapping from EES to electromyography (EMG) responses.","['inbuilt architectural bias using sheep data', 'spinal cord without requiring hand tuning', 'new neural network called deepspine constrained', 'show better sample efficiency', 'present initial results demonstrating']"
83,10,Lakshmi Narasimhan Govindarajan,CLPS/Carney Institute for Brain Science,"Primate vision depends on recurrent processing for reliable perception. At the same time, there is a growing body of literature demonstrating that recurrent connections improve the learning efficiency and generalization of vision models on classic computer vision challenges. Why then, are current large-scale challenges dominated by feedforward networks? We posit that the effectiveness of recurrent vision models is bottlenecked by the widespread algorithm used for training them, ""back-propagation through time"" (BPTT), which has O(N) memory-complexity for training an N step model. Thus, recurrent vision model design is bounded by memory constraints, forcing a choice between rivaling the enormous capacity of leading feedforward models or trying to compensate for this deficit through granular and complex dynamics. Here, we develop a new learning algorithm, ""contractor recurrent back-propagation"" (C-RBP), which alleviates these issues by achieving constant O(1) memory-complexity with steps of recurrent processing. We demonstrate that recurrent vision models trained with C-RBP can detect long-range spatial dependencies in a synthetic contour tracing task that BPTT-trained models cannot. We further demonstrate that recurrent vision models trained with C-RBP to solve the large-scale Panoptic Segmentation MS-COCO challenge outperform the leading feedforward approach. C-RBP is a general-purpose learning algorithm for any application that can benefit from expansive recurrent dynamics.","['n step model thus recurrent vision model design', 'largescale panoptic segmentation mscoco challenge outperform', 'new learning algorithm contractor recurrent backpropagation crbp', 'current largescale challenges dominated', 'synthetic contour tracing task']"
84,10,Debbie Yee,CLPS,"A fundamental question in cognition relates to how motivational incentives influence effort to achieve behavioral goals. Positive and negative outcomes powerfully motivate how much and how long to invest effort in cognitively demanding tasks. Although both outcomes can result in similar behavioral improvements (i.e., motivation to gain vs. avoid losing money both increase effort), the precise neural, catecholaminergic, and computational mechanisms for how rewarding vs. aversive neural systems facilitate cognitive effort is unspecified. Dopamine and serotonin have been theorized to modulate interactions between motivation and cognitive effort; however, how both influence such interactions are unknown. I will use fMRI, psychopharmacology, and computation to identify and integrate complementary mechanisms into a unified neurocomputational framework for motivated cognitive effort. I will use fMRI network-based analyses to test whether positive vs. negative incentives are associated with distinct neural circuits and associated with effort. Using psychopharmacology, I will test whether dopamine and serotonin influence distinct strategies (e.g., vigor, caution) in cognitive effort. Lastly, I will use drift diffusion models to integrate fMRI and behavioral data and quantify how positive vs. negative incentives influence distinct strategies for cognitive effort, and test whether model parameters (drift rate, threshold) are modulated by fMRI BOLD and pharmacological intervention. ","['rewarding vs aversive neural systems facilitate cognitive effort', 'test whether model parameters drift rate threshold', 'serotonin influence distinct strategies eg vigor caution', 'positive vs negative incentives influence distinct strategies', 'test whether positive vs negative incentives']"
85,10,Rohit Kakodkar,CIS - CCV HPC,"Over the last two decades, high-performance computing has become increasingly mainstream due to advancements in computational equipment and infrastructure. For example, the peak performance of large supercomputing centers has increased 100 fold over the last decade. However, efficiently utilizing such facilities requires development of highly scalable applications that can run across multiple machines seamlessly. Often, lower performance is attributed to poorly written applications rather than the hardware itself. In this talk, I will present our approach towards porting one such application, which obtains thermal properties of nanostructured materials, towards massively parallel systems. Our results show that with minor changes we were able to achieve close to linear speedup with the number of resources used. This has enabled us to discover novel physics related to thermal transport through nanostructured materials which were previously not-observable due to computational limitations.","['run across multiple machines seamlessly often lower performance', 'nanostructured materials towards massively parallel systems', 'last two decades highperformance computing', 'last decade however efficiently utilizing', 'approach towards porting one']"
86,10,Cristian Buc Calderon,CLPS department,"LEARNING SPATIOTEMPORAL STRUCTURE THROUGH FEEDBACK-
DRIVEN CLUSTERING IN RNNS

Cristian B. Calderon1,2, Tom Verguts2, Michael J. Frank1,3 

1. Department of Cognitive, Linguistic, and Psychological Sciences, Brown University, Providence, RI, USA

2. Department of Experimental Psychology, Ghent University, Ghent, Belgium

3. Robert J. and Nancy D. Carney Institute for Brain Science, Brown University, Providence, RI, USA


Abstract

Action sequences constitute much of our everyday behavior. One important aspect of such sequences is their spatiotemporal pattern; a plane pilot must not only perform each action in the correct order but also at the precise time. Our project focuses on developing a neuro-computational model that learns to encode spatiotemporal representations of such tasks in the connectivity matrix of recurrent neural networks. We suggest this learning emerges from the combination of specific learning rules within the RNN, in combination of learned sparse feedback projection from motor cortex to the RNN signaling event boundaries (e.g., a motor response). In addition, we aim to understand how such a learned structure can be harnessed to efficiently generalize spatiotemporal representations. For instance, learning a drum rhythm with the hands and transfer it to feet effectors (between output generalization), or applying a learned rhythm to distinct sequences within the same effector (between sequence generalization).","['brain science brown university providence ri usa abstract action sequences constitute much', 'rnns cristian b calderon tom verguts michael j frank department', 'psychological sciences brown university providence ri usa department', 'experimental psychology ghent university ghent belgium robert j', 'everyday behavior one important aspect']"
87,10,Alana Jaskir,CLPS,"While dopamine (DA) has been shown to play a computational role in animal reinforcement learning (RL), its dual effects in two opponent pathways within the striatum suggest a more complex system than that captured by standard RL models. The Opponent Actor Learning (OpAL) model (Collins & Frank, 2014) presented a dual-actor/critic framework based on this biology. The two nonlinear actors specialize in encoding the benefits and costs of actions, and DA modulates both learning and the motivational state (influence of each actor on decision making). While this model accounts for a variety of data, its normative advantage still needs formal analysis. We present simulations showing how dopamine levels can be optimized according to motivational state depending on the “richness” of the environment (e.g., probability of reward). We show that online modulation of motivational states confers a benefit beyond that afforded by classic RL in learning and risk paradigms. These simulations offer a clue as to the normative function of the biology of RL that differs from the standard model-free RL algorithms in computer science. We propose that risky decision making with increased dopamine (e.g., in adolescence or with pharmacology) is a byproduct of this optimization.","['opponent actor learning opal model collins frank presented', 'normative advantage still needs formal analysis', 'two opponent pathways within', 'two nonlinear actors specialize', 'animal reinforcement learning rl']"
88,10,Drew Linsley,Brown University,"Recent successes in deep learning have started to impact neuroscience. Of particular significance are claims that current segmentation algorithms achieve ""super-human"" accuracy in an area known as connectomics. However, as we will show, these algorithms do not effectively generalize beyond the particular source and brain tissues used for training -- severely limiting their usability by the broader neuroscience community. To fill this gap, we describe a novel connectomics challenge for source- and tissue-agnostic reconstruction of neurons (STAR), which favors broad generalization over fitting specific datasets. We first demonstrate that current state-of-the-art approaches to neuron segmentation perform poorly on the challenge. We further describe a novel convolutional recurrent neural network module that combines short-range horizontal connections within a processing stage and long-range top-down connections between stages. The resulting architecture establishes the state of the art on the STAR challenge and represents a significant step towards widely usable and fully-automated connectomics analysis.","['novel convolutional recurrent neural network module', 'current segmentation algorithms achieve superhuman accuracy', 'significant step towards widely usable', 'combines shortrange horizontal connections within', 'neuron segmentation perform poorly']"
89,10,Wenyu Zhang,Physics,"We present a Boosted Decision Tree application in a search for the standard model production of four top quarks. The production of four top quarks from a single proton-proton (pp to tttt) collision has not yet been observed. In  the past few years, the Large Hadron Collider at the CERN collected data of pp collisions at center-of-mass energy of 13 TeV, and at this energy we may be approaching the predicted sensitivity to the pp to tttt process. One critical challenge in this search is to separate the massive standard model top anti-top (tt) events. Boosted decision trees (BDTs) are used to improve the discrimination between tttt signal and tt background. They use the AdaBoost adaptive boosting algorithm, and are trained to identify the principal differences between tttt and tt production. The jet and lepton properties and relevant kinematic variables feature strongly in the choice of BDT input parameters. Simulated tt plus jets and tttt events are used for training multivariate-analysis discriminants. We will discuss how we select the variables of interest, some parameter considerations of BDT training, and how the result will be improved compared with single kinematic variable discriminant.
","['massive standard model top antitop tt events boosted decision trees bdts', 'bdt input parameters simulated tt plus jets', 'boosted decision tree application', 'relevant kinematic variables feature strongly', 'tttt process one critical challenge']"
90,10,Pinar Demetci,Center for Computational Molecular Biology,"Data integration of single-cell measurements is critical for our understanding of cell development and disease, but the lack of correspondence between different types of single-cell measurements makes such efforts challenging. Several unsupervised algorithms are capable of aligning heterogeneous types of single-cell measurements in a shared space, enabling the creation of mappings between single cells in different data modalities. We present Single-Cell alignment using Optimal Transport (SCOT), an unsupervised learning algorithm that uses Gromov Wasserstein-based optimal transport to align single-cell multi-omics datasets. SCOT calculates a probabilistic coupling matrix that matches cells across two datasets based on k nearest neighbor distances. It uses the resulting coupling matrix to align and project one single cell dataset onto another. We compare the alignment performance of SCOT with state-of-the art algorithms on three simulated and two real datasets and demonstrate that SCOT is comparable in quality to competing methods but is significantly faster and requires tuning fewer hyperparameters.","['project one single cell dataset onto another', 'present singlecell alignment using optimal transport scot', 'matches cells across two datasets based', 'align singlecell multiomics datasets scot calculates', 'uses gromov wassersteinbased optimal transport']"
91,11,Sabina Stefan,Biomedical Engineering,"Optical coherence tomography angiography (OCTA) is becoming increasingly popular for neuroscientific study, but it remains challenging to objectively quantify the morphology of cortical microvasculature using OCT compared to other imaging modalities such as two-photon microscopy. This is challenging due to the comparably low signal-to-noise ratio in addition to projection artifacts or “tails” underneath vessels appearing in OCTA due to multiple-scattering. Here, we propose a set of deep learning approaches to automated enhancement, segmentation, and vessel graphing of OCTA images, especially of those obtained from rodent brain cortex. First, we present a convolutional neural network (CNN) to denoise, enhance tubular structures, and mitigate projection artifacts. Next, we propose another CNN for segmentation, which achieves an area-under-curve (AUC) score of 0.96 when compared to expert manual annotation. To improve connectivity of the segmentation, we employ a third CNN which serves to connect spurious gaps. Finally, we describe a strategy for graphing the vascular network from the segmented OCTA. The network graph enables the quantitative assessment of various angioarchitecture properties, including individual vessel lengths, diameters, and tortuosity, as well as the connectivity between vessels. All of these tools, including the trained CNNs, are made publically available as a user-friendly toolbox.","['various angioarchitecture properties including individual vessel lengths diameters', '“ tails ” underneath vessels appearing', 'optical coherence tomography angiography octa', 'cortical microvasculature using oct compared', 'rodent brain cortex first']"
92,11,Kathleen Huntzicker,Neuroscience (GPP),"Hippocampal adult neurogenesis has been implicated in the neural mechanisms for many complex behaviors, including stress response and reward motivation. In this study, we employ a pharmacogenetic method of neurogenesis ablation to study the role of newly-born hippocampal neurons in probabilistic learning. Previous studies from our lab have found that our treated (TK) rats exhibit differential responses to ambiguous threat cues when compared to wild-type controls, as well as decreased effort to gain rewards. In this project, we employ a two-armed bandit task to study rodent responses to ambiguous reward feedback. Rats are exposed to two levers, one of which produces a food reward pellet 80 percent of the time, and the other, 20 percent. This type of probabilistic learning – and subsequent reversal learning when lever outcomes are switched – provides many opportunities to study response to ambiguous feedback. We find that in one version of this task, male and female TK rats exhibit a higher win-stay ratio and earn more rewards than wild-type controls, suggesting that TK rats employ different strategies than wild-types when seeking rewards under ambiguous conditions. Together, our findings suggest a role for adult neurogenesis in explore-exploit decision-making and, more generally, in behavioral response to situational uncertainty.","['many complex behaviors including stress response', 'treated tk rats exhibit differential responses', 'switched – provides many opportunities', 'tk rats employ different strategies', 'female tk rats exhibit']"
93,11,Numair Khan,Computer Science/Brown University,"The large amount of data in light field images means that most existing methods for scene reconstruction using light fields have to make a trade-off between accuracy, global consistency, and computational efficiency. We show that by using only a subset of data points in the spatio-angular domain, the high dimensionality of a light field can be effectively handled to yield a reconstruction that is comparable to the state-of-the-art in terms of quality, while being much more efficient to compute. ","['scene reconstruction using light fields', 'light field images means', 'accuracy global consistency', 'light field', 'spatioangular domain']"
94,11,Victor Boutin,CLPS,"Two classes of computational models compete for explaining the function of the ventral visual stream of the visual cortex: the class of generative vs. discriminative models. On the one hand, discriminative models provide internal representations similar to those found in the Inferior Temporal (IT) area of the visual cortex and yield human-like performances in object recognition tasks. On the other hand, generative models successfully recapitulate neural phenomena reported in the early visual cortex including extra-classical receptive field (RF) effects and provide a plausible framework to account for brain oscillatory dynamics like alpha oscillations and traveling waves.
In this presentation, I will argue that these two complementary views could be reconciled using a hybrid generative+discriminative model in which these two components are re-weighted alongside the hierarchy of the ventral visual stream. In this view, the internal representations of the early visual cortex could be described using a model with a strong generative component and a weak discriminative one. Such representations might provide deeper layers with useful information to solve a large array of visual recognition tasks beyond image categorization. This discriminative component is expected to increase as one descends the ventral stream to better reflect the categorical firing patterns observed in higher areas of the ventral stream. We are interested in collaborating with Brown electrophysiology groups to evaluate our hypothesis using brain similarity metrics with neural data in different areas of the ventral stream.
","['early visual cortex including extraclassical receptive field rf effects', 'hand generative models successfully recapitulate neural phenomena reported', 'one hand discriminative models provide internal representations similar', 'brain oscillatory dynamics like alpha oscillations', 'visual recognition tasks beyond image categorization']"
95,11,Austin Vaitkus,Department of Physics,"Network interpretability is a key requirement of applying deep learning to problems in physics. Unfortunately, convolutional neural networks (CNNs) are notoriously difficult to interpret. However, their applications to time series data makes them an invaluable resource for signal processing and analysis.

We make use of particularly large kernel sizes in shallow CNNs to reduce the complexity of information flow through the network while maintaining a sufficiently high receptive field to extract relevant topological information from a dataset. However, potentially superfluous weights can degrade the interpretability of the network by acting as noise in the visualization of the kernels themselves. To address this, we propose a novel approach to minimize the jaggedness of a network’s convolutional filters by incorporating an additional loss function during the training process. The outcome is a smoother filter, which is easier to interpret by the human eye, yet still performs well in the network’s primary task.

This method has proven successful in simple regression tasks, and will continue to be developed for use in the Particle Astrophysics Group at Brown University.","['human eye yet still performs well', 'physics unfortunately convolutional neural networks cnns', 'dataset however potentially superfluous weights', 'time series data makes', 'sufficiently high receptive field']"
96,11,Dylan Sam,Computer Science,"In modern machine learning and deep learning applications, models are increasingly dependent on large amounts of labeled data. While labeled data can be expensive, unlabeled data is relatively cheap and easy to obtain. Weakly supervised learning looks to solve this need for significant quantities of labeled data by leveraging unlabeled data and external knowledge. One such method is proposed in Data Programming, which uses a generative model approach to leverage the knowledge of several weak learners on a classification task. Our work focuses on applying that method on a computer vision task of the Animals with Attributes 2 dataset. We train individual attribute detectors, which serve as weak labelers in determining animal classes in binary classification. Our pipeline illustrates a phenomena of generalization, where a second model trained on the generative model in a supervised fashion learns to generalize better than the original generative model. Finally, we look at various approaches to directly improve our generative model by reducing the number of weak labelers with poor accuracy.","['obtain weakly supervised learning looks', 'train individual attribute detectors', 'deep learning applications models', 'original generative model finally', 'supervised fashion learns']"
97,11,Mukesh Makwana,"CLPS, Brown University","Our abilities to focus on a goal while ignoring distractors (cognitive control), and to orient attention towards rewarding stimuli (value-based attention) are critical for survival. Cognitive control encompasses multistage processes such as conflict monitoring, response threshold
adjustment, and response selection (Shenhav et al., 2013). However, little is known about how each process interacts with value-driven attention. To address this gap, we developed a modified
Flanker task combined with a reach-tracking paradigm. Participants reached to a target on the right or left side of the screen as instructed by a central arrow that was flanked by congruent, incongruent or neutral distractors. To manipulate value-based attention, the flankers were rendered in colors that had pre-trained associations with positive, negative, or no monetary outcomes. Previous studies suggest that, in the reach tracking paradigm, the initiation latency
(time taken to initiate the movement after stimulus presentation) captures adjustments in response threshold, while the reach curvature (degree of deviation in the reach trajectory from the direct path to the target) captures response selection (e.g., Erb et al., 2016). We found that
these two measures were differentially affected by distractor congruency and value. Initiation latency was reduced by congruent relative to neutral flankers, suggesting that congruency lowered response threshold. This reduction was attenuated by positive-reward compared to no-reward conditions. In contrast, curvature was increased on incongruent relative to neutral trials, suggesting that incongruent distractors interfere with response selection, and this effect
was not affected by flanker value. Together, it appears that both congruent and incongruent trials modulate different cognitive control processes, response threshold adjustment and response
selection respectively, whereas reward only modulates the former. Overall, this study uncovers the potential interactions underlying our cognitive control and value-based attention systems.","['incongruent trials modulate different cognitive control processes response threshold adjustment', 'target captures response selection eg erb et al', 'response selection shenhav et al however little', 'orient attention towards rewarding stimuli valuebased attention', 'survival cognitive control encompasses multistage processes']"
98,11,Harrison Ritz,CLPS,"Short Talk (preferred): Inferring people’s objectives during cost-benefit planning.
We live in a dynamic world, controlling our thoughts and actions to optimize costs and benefits. Optimal control theory offers a normative account of how to regulate these dynamical systems. While this modeling approach has been fruitfully applied to online motor control, much less is known about how optimal control can help us understand more abstract planning processes. To measure optimal control over abstract planning, we developed a novel experimental paradigm in which participants learned to control linear dynamical systems to earn rewards and avoid action costs. We used ‘Inverse Optimal Control’ to infer the objective functions that participants used to make their decisions, finding that we were able to accurately predict participants’ choices. Our modelling further revealed that participants were biased towards using quadratic objective functions, consistent with a standard family of optimal control algorithms. This work shows how optimal control theory can formalize people's decisions to exert effort in the service of their goals, motivating a future fMRI experiment to measure neural representation of the objective functions that participants use for planning. 


Lightning Talk: Modeling optimal approach-avoidance planning.
Animals must frequently choose between pursuing what they desire (e.g., drinking from a river) and avoiding what they fear (e.g., exposing themselves to predators). Effective, flexible planning requires that they combine these goal states with their knowledge about the dynamics of their environment (e.g., the agility of predators). Engineering control theory provides a normative framework for how agents can navigate these approach-avoidance conflicts, extending state-of-the-art motor control algorithms to more complex planning. We applied this approach to simulate an optimal agent’s movements as they try to reach a goal while avoiding a ‘predator’ that is chasing them.  We find that optimal control algorithms can produce a rich and flexible repertoire of actions, such as planning evasive maneuvers that lure predators away from desirable locations. These models have inspired a collaboration with a primate research group to test how control algorithms can be used to understand the neural correlates of dynamic approach-avoidance planning.
","['planning lightning talk modeling optimal approachavoidance planning animals must frequently choose', 'biased towards using quadratic objective functions consistent', 'approachavoidance conflicts extending stateoftheart motor control algorithms', 'short talk preferred inferring people ’', 'used ‘ inverse optimal control ’']"
